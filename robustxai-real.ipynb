{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":37484,"sourceType":"datasetVersion","datasetId":29414}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"AttributeError# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"adde8ac2-1558-423e-a319-07ce8c17d77a","_cell_guid":"05ec5838-0604-4bea-8cd0-88a741b77830","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-03T04:33:40.093126Z","iopub.execute_input":"2024-10-03T04:33:40.093448Z","iopub.status.idle":"2024-10-03T04:33:41.130268Z","shell.execute_reply.started":"2024-10-03T04:33:40.093414Z","shell.execute_reply":"2024-10-03T04:33:41.129325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install captum==0.5.0\n# !pip install h5py==3.7.0\n# !pip install imbalanced-learn==0.9.1\n# !pip install joblib==1.2.0\n# !pip install matplotlib-base==3.5.3\n# !pip install networkx==2.8.4\n# !pip install numpy==1.23.4\n# !pip install pandas==1.5.1\n# !pip install pyg==2.2.0\n# !pip install torch==1.13.0\n# !pip install scikit-learn==1.1.3\n# !pip install seaborn==0.12.1\n# !pip install torchaudio==0.13.0\n# !pip install torchvision==0.14.0\n# !pip install tqdm==4.64.1\n# !pip install build==0.10.0\n# !pip install docopt==0.6.2\n# !pip install kaggle==1.5.12\n# !pip install pip-tools==6.12.3\n# !pip install pipreqs==0.4.11\n# !pip install pyproject-hooks==1.0.0\n# !pip install python-slugify==7.0.0\n# !pip install text-unidecode==1.3\n# !pip install yarg==0.1.9\n# !pip install pytorch-lightning==2.0.2\n# !pip install e2cnn==0.2.3\n# !pip install wandb==0.15.0\n# !pip install nltk==3.8.1","metadata":{"_uuid":"495eef4c-45ff-449f-adbe-16ae9f0b3cb2","_cell_guid":"c98ca857-03db-41fc-859d-61e813ca6465","collapsed":false,"execution":{"iopub.status.busy":"2024-10-02T11:46:03.958609Z","iopub.execute_input":"2024-10-02T11:46:03.959933Z","iopub.status.idle":"2024-10-02T11:56:00.119837Z","shell.execute_reply.started":"2024-10-02T11:46:03.959876Z","shell.execute_reply":"2024-10-02T11:56:00.116312Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/JonathanCrabbe/RobustXAI.git","metadata":{"_uuid":"8f7a2662-22e3-47dc-9287-aa14b12fce90","_cell_guid":"478898b3-02f6-4c89-bb99-5a511aa1a2bf","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-03T13:07:32.770201Z","iopub.execute_input":"2024-10-03T13:07:32.770667Z","iopub.status.idle":"2024-10-03T13:07:34.829523Z","shell.execute_reply.started":"2024-10-03T13:07:32.770617Z","shell.execute_reply":"2024-10-03T13:07:34.828111Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'RobustXAI'...\nremote: Enumerating objects: 738, done.\u001b[K\nremote: Total 738 (delta 0), reused 0 (delta 0), pack-reused 738 (from 1)\u001b[K\nReceiving objects: 100% (738/738), 2.06 MiB | 11.12 MiB/s, done.\nResolving deltas: 100% (519/519), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch_geometric\n!pip install e2cnn==0.2.3\n!pip install captum==0.5.0","metadata":{"_uuid":"6ebd3761-3bfe-4caf-871a-00b344935b90","_cell_guid":"c78406c8-b8ba-4a47-a0f5-266e5b323949","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-03T13:07:44.461972Z","iopub.execute_input":"2024-10-03T13:07:44.462417Z","iopub.status.idle":"2024-10-03T13:08:31.269915Z","shell.execute_reply.started":"2024-10-03T13:07:44.462375Z","shell.execute_reply":"2024-10-03T13:08:31.268628Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.9.5)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2024.6.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (5.9.3)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (4.66.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (2024.8.30)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\nCollecting e2cnn==0.2.3\n  Downloading e2cnn-0.2.3-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from e2cnn==0.2.3) (2.4.0+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from e2cnn==0.2.3) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from e2cnn==0.2.3) (1.14.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from e2cnn==0.2.3) (1.12)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->e2cnn==0.2.3) (1.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->e2cnn==0.2.3) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->e2cnn==0.2.3) (4.12.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->e2cnn==0.2.3) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->e2cnn==0.2.3) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->e2cnn==0.2.3) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->e2cnn==0.2.3) (2.1.5)\nDownloading e2cnn-0.2.3-py3-none-any.whl (225 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: e2cnn\nSuccessfully installed e2cnn-0.2.3\nCollecting captum==0.5.0\n  Downloading captum-0.5.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from captum==0.5.0) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from captum==0.5.0) (1.26.4)\nRequirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.10/site-packages (from captum==0.5.0) (2.4.0+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.5.0) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.5.0) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.5.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.5.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.5.0) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.5.0) (2024.6.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.5.0) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.5.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.5.0) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.5.0) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.5.0) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.5.0) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.5.0) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.5.0) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->captum==0.5.0) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6->captum==0.5.0) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6->captum==0.5.0) (1.3.0)\nDownloading captum-0.5.0-py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: captum\nSuccessfully installed captum-0.5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# %cd /opt/conda/envs/robustxai","metadata":{"_uuid":"d1917c60-d967-49a1-9e1e-e83d03b28067","_cell_guid":"4c4c3cb6-8ddd-44fb-8c62-9acf4a588b4e","collapsed":false,"execution":{"iopub.status.busy":"2024-10-02T12:00:30.347962Z","iopub.execute_input":"2024-10-02T12:00:30.350169Z","iopub.status.idle":"2024-10-02T12:00:30.360592Z","shell.execute_reply.started":"2024-10-02T12:00:30.350082Z","shell.execute_reply":"2024-10-02T12:00:30.358613Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %cd /kaggle/working/RobustXAI","metadata":{"_uuid":"341b0e68-8686-4ea5-96c5-4acea5331269","_cell_guid":"ee56272a-57ce-467e-8fe4-3b46acb4f322","collapsed":false,"execution":{"iopub.status.busy":"2024-10-02T12:01:50.848493Z","iopub.execute_input":"2024-10-02T12:01:50.849096Z","iopub.status.idle":"2024-10-02T12:01:50.859979Z","shell.execute_reply.started":"2024-10-02T12:01:50.849043Z","shell.execute_reply":"2024-10-02T12:01:50.858317Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"_uuid":"06023c57-28f9-4609-8677-9fbc82df208f","_cell_guid":"9657e015-4bcd-48b8-b529-139dd2dcaea5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-03T13:08:48.714213Z","iopub.execute_input":"2024-10-03T13:08:48.714746Z","iopub.status.idle":"2024-10-03T13:08:49.898919Z","shell.execute_reply.started":"2024-10-03T13:08:48.714699Z","shell.execute_reply":"2024-10-03T13:08:49.896880Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"# !mv /kaggle/working/RobustXAI/* ..\n# # !mv /kaggle/working/RobustXAI/.[!.]* .","metadata":{"_uuid":"ff1e5c33-6855-4f7d-8162-edc95a5265f6","_cell_guid":"99d165a9-fe26-4c41-ad6c-2d0b6ce9e9f2","collapsed":false,"execution":{"iopub.status.busy":"2024-10-02T12:54:53.118971Z","iopub.execute_input":"2024-10-02T12:54:53.119992Z","iopub.status.idle":"2024-10-02T12:54:54.168080Z","shell.execute_reply.started":"2024-10-02T12:54:53.119941Z","shell.execute_reply":"2024-10-02T12:54:54.166730Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv /kaggle/working/RobustXAI/* /kaggle/working/","metadata":{"_uuid":"3ea3b87d-4dbb-4c67-af6b-d8dff67d556f","_cell_guid":"330ad317-c95d-4a90-82a8-a751408ec0e1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-03T13:09:05.963283Z","iopub.execute_input":"2024-10-03T13:09:05.964467Z","iopub.status.idle":"2024-10-03T13:09:07.182193Z","shell.execute_reply.started":"2024-10-03T13:09:05.964415Z","shell.execute_reply":"2024-10-03T13:09:07.180488Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/input/","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:10:59.126921Z","iopub.execute_input":"2024-10-03T13:10:59.127418Z","iopub.status.idle":"2024-10-03T13:10:59.135813Z","shell.execute_reply.started":"2024-10-03T13:10:59.127372Z","shell.execute_reply":"2024-10-03T13:10:59.134318Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:11:04.787116Z","iopub.execute_input":"2024-10-03T13:11:04.788276Z","iopub.status.idle":"2024-10-03T13:11:05.944105Z","shell.execute_reply.started":"2024-10-03T13:11:04.788224Z","shell.execute_reply":"2024-10-03T13:11:05.942696Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"heartbeat  robustxai-real\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/input/robustxai-real/","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:11:24.542062Z","iopub.execute_input":"2024-10-03T13:11:24.542646Z","iopub.status.idle":"2024-10-03T13:11:24.565046Z","shell.execute_reply.started":"2024-10-03T13:11:24.542588Z","shell.execute_reply":"2024-10-03T13:11:24.563830Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"/kaggle/input/robustxai-real\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:11:32.080412Z","iopub.execute_input":"2024-10-03T13:11:32.081542Z","iopub.status.idle":"2024-10-03T13:11:33.278370Z","shell.execute_reply.started":"2024-10-03T13:11:32.081494Z","shell.execute_reply":"2024-10-03T13:11:33.276611Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"README.md\t    __results__.html  experiments\t       models\nRobustXAI\t    custom.css\t      explanations_fail.ipynb  results\n__notebook__.ipynb  datasets\t      illustration.png\t       results_dir.json\n__output__.json     environment.yml   interpretability\t       utils\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/input/robustxai-real/results/ecg/cnn32_seed42/","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:12:13.249437Z","iopub.execute_input":"2024-10-03T13:12:13.249940Z","iopub.status.idle":"2024-10-03T13:12:13.259898Z","shell.execute_reply.started":"2024-10-03T13:12:13.249894Z","shell.execute_reply":"2024-10-03T13:12:13.258785Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"/kaggle/input/robustxai-real/results/ecg/cnn32_seed42\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:12:13.961087Z","iopub.execute_input":"2024-10-03T13:12:13.961570Z","iopub.status.idle":"2024-10-03T13:12:15.182225Z","shell.execute_reply.started":"2024-10-03T13:12:13.961517Z","shell.execute_reply":"2024-10-03T13:12:15.180434Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"cnn32_seed42_allcnn.json\t       cnn32_seed42_augmented_checkpoint5.pt\ncnn32_seed42_allcnn.pt\t\t       cnn32_seed42_augmented_checkpoint6.pt\ncnn32_seed42_allcnn_checkpoint1.pt     cnn32_seed42_augmented_checkpoint7.pt\ncnn32_seed42_allcnn_checkpoint10.pt    cnn32_seed42_augmented_checkpoint8.pt\ncnn32_seed42_allcnn_checkpoint11.pt    cnn32_seed42_standard.json\ncnn32_seed42_allcnn_checkpoint2.pt     cnn32_seed42_standard.pt\ncnn32_seed42_allcnn_checkpoint3.pt     cnn32_seed42_standard_checkpoint1.pt\ncnn32_seed42_allcnn_checkpoint4.pt     cnn32_seed42_standard_checkpoint10.pt\ncnn32_seed42_allcnn_checkpoint5.pt     cnn32_seed42_standard_checkpoint11.pt\ncnn32_seed42_allcnn_checkpoint6.pt     cnn32_seed42_standard_checkpoint12.pt\ncnn32_seed42_allcnn_checkpoint7.pt     cnn32_seed42_standard_checkpoint2.pt\ncnn32_seed42_allcnn_checkpoint8.pt     cnn32_seed42_standard_checkpoint3.pt\ncnn32_seed42_allcnn_checkpoint9.pt     cnn32_seed42_standard_checkpoint4.pt\ncnn32_seed42_augmented.json\t       cnn32_seed42_standard_checkpoint5.pt\ncnn32_seed42_augmented.pt\t       cnn32_seed42_standard_checkpoint6.pt\ncnn32_seed42_augmented_checkpoint1.pt  cnn32_seed42_standard_checkpoint7.pt\ncnn32_seed42_augmented_checkpoint2.pt  cnn32_seed42_standard_checkpoint8.pt\ncnn32_seed42_augmented_checkpoint3.pt  cnn32_seed42_standard_checkpoint9.pt\ncnn32_seed42_augmented_checkpoint4.pt  feature_importance\n","output_type":"stream"}]},{"cell_type":"code","source":"!mv /kaggle/input/robustxai-real/results/* /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:12:30.658691Z","iopub.execute_input":"2024-10-03T13:12:30.659134Z","iopub.status.idle":"2024-10-03T13:12:32.196738Z","shell.execute_reply.started":"2024-10-03T13:12:30.659093Z","shell.execute_reply":"2024-10-03T13:12:32.195036Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"mv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_augmented_checkpoint1.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_standard.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_standard_checkpoint8.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_augmented_checkpoint8.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_allcnn_checkpoint8.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_augmented_checkpoint2.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_standard_checkpoint2.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_allcnn_checkpoint5.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_allcnn_checkpoint6.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_standard.json': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_standard_checkpoint6.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_standard_checkpoint10.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_standard_checkpoint3.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_augmented_checkpoint4.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_augmented_checkpoint7.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_augmented.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_standard_checkpoint11.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_allcnn_checkpoint9.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_standard_checkpoint7.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_allcnn_checkpoint1.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_allcnn_checkpoint11.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_augmented_checkpoint6.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_standard_checkpoint5.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/feature_importance/metrics.csv': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/feature_importance/feature_importance_ecg_augmented-cnn.pdf': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/feature_importance/feature_importance_ecg_all-cnn.pdf': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/feature_importance/feature_importance_ecg_relaxing_invariance.pdf': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/feature_importance/feature_importance_ecg_standard-cnn.pdf': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_standard_checkpoint1.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_allcnn_checkpoint2.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_allcnn.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_allcnn_checkpoint3.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_standard_checkpoint12.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_standard_checkpoint4.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_allcnn_checkpoint10.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_allcnn_checkpoint7.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_standard_checkpoint9.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_augmented_checkpoint5.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_allcnn_checkpoint4.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_allcnn.json': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_augmented_checkpoint3.pt': Read-only file system\nmv: cannot remove '/kaggle/input/robustxai-real/results/ecg/cnn32_seed42/cnn32_seed42_augmented.json': Read-only file system\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -d /kaggle/working/RobustXAI","metadata":{"_uuid":"8e77c10e-c16d-4908-a7fb-0c42f6aa8d60","_cell_guid":"2ffb80f0-4701-48c5-bf43-b2dd8e9a9221","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-03T08:55:19.830109Z","iopub.execute_input":"2024-10-03T08:55:19.830973Z","iopub.status.idle":"2024-10-03T08:55:20.875301Z","shell.execute_reply.started":"2024-10-03T08:55:19.830928Z","shell.execute_reply":"2024-10-03T08:55:20.874265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd /kaggle/working/RobustXAI\n!ls","metadata":{"execution":{"iopub.status.busy":"2024-10-03T08:55:38.518725Z","iopub.execute_input":"2024-10-03T08:55:38.519104Z","iopub.status.idle":"2024-10-03T08:55:40.574829Z","shell.execute_reply.started":"2024-10-03T08:55:38.519068Z","shell.execute_reply":"2024-10-03T08:55:40.573630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !python -m experiments.ecg --name feature_importance --train --plot","metadata":{"_uuid":"31d54e82-7762-4bf4-8ada-21f84ace4737","_cell_guid":"ec2b2685-abb3-40cb-86a5-d602e1c769f6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-03T04:34:58.993688Z","iopub.execute_input":"2024-10-03T04:34:58.994615Z","iopub.status.idle":"2024-10-03T04:35:12.277838Z","shell.execute_reply.started":"2024-10-03T04:34:58.994561Z","shell.execute_reply":"2024-10-03T04:35:12.276732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport os\nimport logging\nimport argparse\nimport pandas as pd\nimport itertools\nfrom pathlib import Path\nfrom torch.utils.data import DataLoader, RandomSampler, Subset\n# from datasets.loaders import ECGDataset\nfrom models.time_series import AllCNN, StandardCNN\nfrom utils.symmetries import Translation1D\nfrom utils.misc import set_random_seed\n# from utils.plots import (\n#     single_robustness_plots,\n#     relaxing_invariance_plots,\n#     enforce_invariance_plot,\n#     sensitivity_plot,\n# )\nfrom interpretability.robustness import (\n    accuracy,\n    InvariantExplainer,\n    model_invariance_exact,\n    explanation_invariance_exact,\n    explanation_equivariance_exact,\n    sensitivity,\n)\nfrom interpretability.example import (\n    SimplEx,\n    RepresentationSimilarity,\n    TracIn,\n    InfluenceFunctions,\n)\nfrom interpretability.feature import FeatureImportance\nfrom interpretability.concept import CAR, CAV, ConceptExplainer\nfrom captum.attr import (\n    IntegratedGradients,\n    GradientShap,\n    FeaturePermutation,\n    FeatureAblation,\n    Occlusion,\n    DeepLift\n)","metadata":{"_uuid":"c793ec2d-4bc5-4b13-8ec3-5852c92ee9fe","_cell_guid":"76956069-b7a9-4fbc-bc65-f5b38b04db49","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-03T13:14:10.466970Z","iopub.execute_input":"2024-10-03T13:14:10.467513Z","iopub.status.idle":"2024-10-03T13:14:14.642747Z","shell.execute_reply.started":"2024-10-03T13:14:10.467463Z","shell.execute_reply":"2024-10-03T13:14:14.641004Z"},"trusted":true},"execution_count":17,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, RandomSampler, Subset\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# from datasets.loaders import ECGDataset\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtime_series\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AllCNN, StandardCNN\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymmetries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translation1D\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_random_seed\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"],"ename":"ModuleNotFoundError","evalue":"No module named 'models'","output_type":"error"}]},{"cell_type":"code","source":"import logging\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n# 检查是否已有处理器，避免重复添加\n# if not logger.handlers:\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.INFO)\nformatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n# 测试日志\nlogger.info(\"This is an info 33message\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:14:14.643740Z","iopub.status.idle":"2024-10-03T13:14:14.644217Z","shell.execute_reply.started":"2024-10-03T13:14:14.643997Z","shell.execute_reply":"2024-10-03T13:14:14.644023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### datasets.loaders","metadata":{"_uuid":"57975810-4b2f-4d2b-a8fc-70aef1810513","_cell_guid":"5eff5c4d-4d9a-4cc2-a85e-47ff02834bd2","trusted":true}},{"cell_type":"code","source":"import os\nimport random\nimport re\nfrom abc import ABC, abstractmethod\nfrom collections import Counter\nfrom functools import partial\nfrom pathlib import Path\n\nimport h5py\nimport networkx as nx\nimport nltk\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn.functional as F\nfrom imblearn.over_sampling import SMOTE\nfrom joblib import Parallel, delayed\nfrom torch.utils.data import Dataset, SubsetRandomSampler\nfrom torch.utils.data.dataset import random_split\nfrom torch_geometric.datasets import TUDataset\nfrom torchvision.datasets import CIFAR100, STL10, FashionMNIST, ImageFolder\nfrom torchvision.transforms import transforms\nfrom tqdm import tqdm\n\nfrom utils.misc import to_molecule\n\nclass ConceptDataset(ABC, Dataset):\n    @property\n    @abstractmethod\n    def concept_names(self):\n        ...\n\n    @abstractmethod\n    def generate_concept_dataset(self, concept_id: int, concept_set_size: int) -> tuple:\n        ...\n\n        \nclass ECGDataset(ConceptDataset):\n    def __init__(\n        self,\n        data_dir: Path,\n        train: bool,\n        balance_dataset: bool,\n        random_seed: int = 42,\n        binarize_label: bool = True,\n    ):\n        \"\"\"\n        Generate a ECG dataset\n        Args:\n            data_dir: directory where the dataset should be stored\n            train: True if the training set should be returned, False for the testing set\n            balance_dataset: True if the classes should be balanced with SMOTE\n            random_seed: random seed for reproducibility\n            binarize_label: True if the label should be binarized (0: normal heartbeat, 1: abnormal heartbeat)\n        \"\"\"\n        self.data_dir = data_dir\n        if not data_dir.exists():\n            os.makedirs(data_dir)\n#             self.download()\n        # Read CSV; extract features and labels\n#         file_path = (\n#             data_dir / \"mitbih_train.csv\" if train else data_dir / \"mitbih_test.csv\"\n#         )\n        file_path = (\n            data_dir / \"mitbih_train.csv\" if train else data_dir / \"mitbih_test.csv\"\n        )\n#         data_train = pd.read_csv('../input/heartbeat/mitbih_train.csv', header=None)\n#         data_test = pd.read_csv('../input/heartbeat/mitbih_test.csv', header=None)\n        df = pd.read_csv(file_path)\n        X = df.iloc[:, :187].values\n        y = df.iloc[:, 187].values\n        if balance_dataset:\n            n_normal = np.count_nonzero(y == 0)\n            balancing_dic = {\n                0: n_normal,\n                1: int(n_normal / 4),\n                2: int(n_normal / 4),\n                3: int(n_normal / 4),\n                4: int(n_normal / 4),\n            }\n            smote = SMOTE(random_state=random_seed, sampling_strategy=balancing_dic)\n            X, y = smote.fit_resample(X, y)\n        if binarize_label:\n            y = np.where(y >= 1, 1, 0)\n        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n        self.y = torch.tensor(y, dtype=torch.long)\n        self.binarize_label = binarize_label\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\n    def download(self) -> None:\n        import kaggle\n\n        logging.info(f\"Downloading ECG dataset in {self.data_dir}\")\n        kaggle.api.authenticate()\n        kaggle.api.dataset_download_files(\n            \"shayanfazeli/heartbeat\", path=self.data_dir, unzip=True\n        )\n        logging.info(f\"ECG dataset downloaded in {self.data_dir}\")\n\n    def generate_concept_dataset(self, concept_id: int, concept_set_size: int) -> tuple:\n        \"\"\"\n        Return a concept dataset with positive/negatives for ECG\n        Args:\n            random_seed: random seed for reproducibility\n            concept_set_size: size of the positive and negative subset\n        Returns:\n            a concept dataset of the form X (features),C (concept labels)\n        \"\"\"\n        assert not self.binarize_label\n        mask = self.y == concept_id + 1\n        positive_idx = torch.nonzero(mask).flatten()\n        negative_idx = torch.nonzero(~mask).flatten()\n        positive_loader = torch.utils.data.DataLoader(\n            self, batch_size=concept_set_size, sampler=SubsetRandomSampler(positive_idx)\n        )\n        negative_loader = torch.utils.data.DataLoader(\n            self, batch_size=concept_set_size, sampler=SubsetRandomSampler(negative_idx)\n        )\n        X_pos, C_pos = next(iter(positive_loader))\n        X_neg, C_neg = next(iter(negative_loader))\n        X = torch.concatenate((X_pos, X_neg), 0)\n        C = torch.concatenate(\n            (torch.ones(concept_set_size), torch.zeros(concept_set_size)), 0\n        )\n        rand_perm = torch.randperm(len(X))\n        return X[rand_perm], C[rand_perm]\n\n    def concept_names(self):\n        return [\"Supraventricular\", \"Premature Ventricular\", \"Fusion Beats\", \"Unknown\"]","metadata":{"_uuid":"1053662c-500d-4cf4-9aaa-ffdef1ebe3ea","_cell_guid":"490312fd-b9c8-4b6f-a2a2-db0808551b95","execution":{"iopub.status.busy":"2024-10-03T13:14:15.158983Z","iopub.execute_input":"2024-10-03T13:14:15.159410Z","iopub.status.idle":"2024-10-03T13:14:23.846194Z","shell.execute_reply.started":"2024-10-03T13:14:15.159369Z","shell.execute_reply":"2024-10-03T13:14:23.844246Z"},"trusted":true},"execution_count":18,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_molecule\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mConceptDataset\u001b[39;00m(ABC, Dataset):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;129m@abstractmethod\u001b[39m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcept_names\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"],"ename":"ModuleNotFoundError","evalue":"No module named 'utils'","output_type":"error"}]},{"cell_type":"markdown","source":"### utils.plots","metadata":{}},{"cell_type":"code","source":"import argparse\nimport itertools\nimport json\nimport logging\nimport textwrap\nfrom pathlib import Path\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\nsns.set_palette(\"colorblind\")\nmarkers = {\n    \"DeepLift\": \"o\",\n    \"Feature Ablation\": \"s\",\n    \"Feature Occlusion\": \"X\",\n    \"Feature Permutation\": \"D\",\n    \"Gradient Shap\": \"v\",\n    \"Integrated Gradients\": \"p\",\n    \"Influence Functions\": \"^\",\n    \"Rep. Similar-Lin1\": \"*\",\n    \"SimplEx-Lin1\": \"H\",\n    \"TracIn\": \">\",\n    \"CAR-Lin1\": \"<\",\n    \"CAV-Lin1\": \"d\",\n}\n\n\ndef single_robustness_plots(plot_dir: Path, dataset: str, experiment_name: str) -> None:\n    metrics_df = pd.read_csv(plot_dir / \"metrics.csv\")\n    for model_type in metrics_df[\"Model Type\"].unique():\n        sub_df = metrics_df[metrics_df[\"Model Type\"] == model_type]\n        y = (\n            \"Explanation Equivariance\"\n            if \"Explanation Equivariance\" in metrics_df.columns\n            else \"Explanation Invariance\"\n        )\n        ax = sns.boxplot(sub_df, x=\"Explanation\", y=y, showfliers=False)\n        wrap_labels(ax, 10)\n        plt.ylim(-1.1, 1.1)\n        plt.tight_layout()\n        plt.savefig(\n            plot_dir\n            / f'{experiment_name}_{dataset}_{model_type.lower().replace(\" \", \"_\")}.pdf'\n        )\n        plt.close()\n\n\ndef global_robustness_plots(experiment_name: str) -> None:\n    sns.set(font_scale=0.9)\n    sns.set_style(\"whitegrid\")\n    sns.set_palette(\"colorblind\")\n    with open(Path.cwd() / \"results_dir.json\") as f:\n        path_dic = json.load(f)\n    global_df = []\n    for dataset in path_dic:\n        dataset_df = pd.read_csv(\n            Path.cwd() / path_dic[dataset] / experiment_name / \"metrics.csv\"\n        )\n        dataset_df[\"Dataset\"] = [dataset] * len(dataset_df)\n        global_df.append(dataset_df)\n    global_df = pd.concat(global_df)\n    rename_dic = {\n        \"SimplEx-Lin1\": \"SimplEx-Inv\",\n        \"SimplEx-Conv3\": \"SimplEx-Equiv\",\n        \"Representation Similarity-Lin1\": \"Rep. Similar-Inv\",\n        \"Representation Similarity-Conv3\": \"Rep. Similar-Equiv\",\n        \"CAR-Lin1\": \"CAR-Inv\",\n        \"CAR-Conv3\": \"CAR-Equiv\",\n        \"CAV-Lin1\": \"CAV-Inv\",\n        \"CAV-Conv3\": \"CAV-Equiv\",\n        \"SimplEx-Phi\": \"SimplEx-Equiv\",\n        \"SimplEx-Rho\": \"SimplEx-Inv\",\n        \"Representation Similarity-Phi\": \"Rep. Similar-Equiv\",\n        \"Representation Similarity-Rho\": \"Rep. Similar-Inv\",\n        \"CAR-Phi\": \"CAR-Equiv\",\n        \"CAR-Rho\": \"CAR-Inv\",\n        \"CAV-Phi\": \"CAV-Equiv\",\n        \"CAV-Rho\": \"CAV-Inv\",\n        \"CAR-Conv1\": \"CAR-Equiv\",\n        \"CAV-Conv1\": \"CAV-Equiv\",\n        \"SimplEx-Conv1\": \"SimplEx-Equiv\",\n        \"Representation Similarity-Conv1\": \"Rep. Similar-Equiv\",\n        \"CAR-Layer3\": \"CAR-Inv\",\n        \"CAV-Layer3\": \"CAV-Inv\",\n        \"SimplEx-Layer3\": \"SimplEx-Inv\",\n        \"Representation Similarity-Layer3\": \"Rep. Similar-Inv\",\n        \"CAR-Embedding\": \"CAR-Inv\",\n        \"CAV-Embedding\": \"CAV-Inv\",\n        \"SimplEx-Embedding\": \"SimplEx-Inv\",\n        \"Representation Similarity-Embedding\": \"Rep. Similar-Inv\",\n    }\n    global_df = global_df.replace(rename_dic)\n    global_df = global_df[\n        (global_df[\"Model Type\"] == \"All-CNN\")\n        | (global_df[\"Model Type\"] == \"GNN\")\n        | (global_df[\"Model Type\"] == \"Deep-Set\")\n        | (global_df[\"Model Type\"] == \"D8-Wide-ResNet\")\n        | (global_df[\"Model Type\"] == \"bow_classifier\")\n    ]\n    y = (\n        \"Explanation Equivariance\"\n        if \"Explanation Equivariance\" in global_df.columns\n        else \"Explanation Invariance\"\n    )\n    ax = sns.boxplot(global_df, x=\"Dataset\", hue=\"Explanation\", y=y, showfliers=False)\n    wrap_labels(ax, 10)\n    plt.ylim(-1.1, 1.1)\n    box_patches = [\n        patch for patch in ax.patches if type(patch) == matplotlib.patches.PathPatch\n    ]\n    if (\n        len(box_patches) == 0\n    ):  # in matplotlib older than 3.5, the boxes are stored in ax2.artists\n        box_patches = ax.artists\n    num_patches = len(box_patches)\n    lines_per_boxplot = len(ax.lines) // num_patches\n    for i, patch in enumerate(box_patches):\n        # Set the linecolor on the patch to the facecolor, and set the facecolor to None\n        col = patch.get_facecolor()\n        patch.set_edgecolor(col)\n        patch.set_facecolor(\"None\")\n\n        # Each box has associated Line2D objects (to make the whiskers, fliers, etc.)\n        # Loop over them here, and use the same color as above\n        for line in ax.lines[i * lines_per_boxplot : (i + 1) * lines_per_boxplot]:\n            line.set_color(col)\n            line.set_mfc(col)  # facecolor of fliers\n            line.set_mec(col)  # edgecolor of fliers\n\n    # Also fix the legend\n    for legpatch in ax.legend_.get_patches():\n        col = legpatch.get_facecolor()\n        legpatch.set_edgecolor(col)\n        legpatch.set_facecolor(\"None\")\n    sns.despine(left=True)\n    plt.tight_layout()\n    plt.savefig(Path.cwd() / f\"results/{experiment_name}_global_robustness.pdf\")\n    plt.close()\n\n\ndef relaxing_invariance_plots(\n    plot_dir: Path, dataset: str, experiment_name: str\n) -> None:\n    sns.set(font_scale=1.2)\n    sns.set_style(\"whitegrid\")\n    sns.set_palette(\"colorblind\")\n    metrics_df = pd.read_csv(plot_dir / \"metrics.csv\")\n    metrics_df = metrics_df.drop(\n        metrics_df[\n            (metrics_df.Explanation == \"SimplEx-Conv3\")\n            | (metrics_df.Explanation == \"Representation Similarity-Conv3\")\n            | (metrics_df.Explanation == \"CAR-Conv3\")\n            | (metrics_df.Explanation == \"CAV-Conv3\")\n        ].index\n    )\n    rename_dic = {\"Representation Similarity-Lin1\": \"Rep. Similar-Lin1\"}\n    metrics_df = metrics_df.replace(rename_dic)\n    y = (\n        \"Explanation Equivariance\"\n        if \"Explanation Equivariance\" in metrics_df.columns\n        else \"Explanation Invariance\"\n    )\n    plot_df = metrics_df.groupby([\"Model Type\", \"Explanation\"]).mean()\n    plot_df[[\"Model Invariance CI\", f\"{y} CI\"]] = (\n        2 * metrics_df.groupby([\"Model Type\", \"Explanation\"]).sem()\n    )\n    unique_explanations = metrics_df[\"Explanation\"].unique()\n    trimmed_markers = {key: value for key, value in markers.items() if key in unique_explanations}\n    sns.scatterplot(\n        plot_df,\n        x=\"Model Invariance\",\n        y=y,\n        hue=\"Model Type\",\n        edgecolor=\"black\",\n        alpha=0.5,\n        style=\"Explanation\",\n        # markers=markers[: metrics_df[\"Explanation\"].unique()],\n        markers=trimmed_markers,\n        s=100,\n    )\n    plt.errorbar(\n        x=plot_df[\"Model Invariance\"],\n        y=plot_df[y],\n        xerr=plot_df[\"Model Invariance CI\"],\n        yerr=plot_df[f\"{y} CI\"],\n        ecolor=\"black\",\n        elinewidth=1.7,\n        linestyle=\"\",\n        capsize=1.7,\n        capthick=1.7,\n    )\n    plt.xscale(\"linear\")\n    plt.axline((0, 0), slope=1, color=\"gray\", linestyle=\"dotted\")\n    plt.xlim(0, 1.1)\n    plt.ylim(0, 1.1)\n    plt.tight_layout()\n    plt.savefig(plot_dir / f\"{experiment_name}_{dataset}_relaxing_invariance.pdf\")\n    plt.close()\n\n\ndef mc_convergence_plot(plot_dir: Path, dataset: str, experiment_name: str) -> None:\n    metrics_df = pd.read_csv(plot_dir / \"metrics.csv\")\n    for estimator_name in metrics_df[\"Estimator Name\"].unique():\n        metrics_subdf = metrics_df[metrics_df[\"Estimator Name\"] == estimator_name]\n        x = metrics_subdf[\"Number of MC Samples\"]\n        y = metrics_subdf[\"Estimator Value\"]\n        ci = 2 * metrics_subdf[\"Estimator SEM\"]\n        plt.plot(x, y, label=estimator_name)\n        plt.fill_between(x, y - ci, y + ci, alpha=0.2)\n    plt.legend()\n    plt.xlabel(r\"$N_{\\mathrm{samp}}$\")\n    plt.ylabel(\"Monte Carlo Estimator\")\n    plt.ylim(-1, 1)\n    plt.tight_layout()\n    plt.savefig(plot_dir / f\"{experiment_name}_{dataset}.pdf\")\n    plt.close()\n\n\ndef understanding_randomness_plots(plot_dir: Path, dataset: str) -> None:\n    data_df = pd.read_csv(plot_dir / \"data.csv\")\n    sub_df = data_df[data_df[\"Baseline\"] == False]\n    print(sub_df)\n    sns.kdeplot(data=data_df, x=\"y1\", y=\"y2\", hue=\"Model Type\", fill=True)\n    for model_type in data_df[\"Model Type\"].unique():\n        baseline = data_df[\n            (data_df[\"Model Type\"] == model_type) & (data_df[\"Baseline\"] == True)\n        ]\n        plt.plot(\n            baseline[\"y1\"],\n            baseline[\"y2\"],\n            marker=\"x\",\n            linewidth=0,\n            label=f\"Baseline {model_type}\",\n        )\n    plt.axhline(0, color=\"black\")\n    plt.axvline(0, color=\"black\")\n    plt.xlabel(r\"$y_1$\")\n    plt.ylabel(r\"$y_2$\")\n    plt.legend()\n    plt.show()\n\n\ndef enforce_invariance_plot(plot_dir: Path, dataset: str) -> None:\n    sns.set(font_scale=1.3)\n    sns.set_style(\"whitegrid\")\n    sns.set_palette(\"colorblind\")\n    metrics_df = pd.read_csv(plot_dir / \"metrics.csv\")\n    sns.lineplot(metrics_df, x=\"N_inv\", y=\"Explanation Invariance\", hue=\"Explanation\")\n    plt.legend()\n    plt.xlabel(r\"$N_{\\mathrm{inv}}$\")\n    plt.tight_layout()\n    plt.savefig(plot_dir / f\"enforce_invariance_{dataset}.pdf\")\n    plt.close()\n\n\ndef sensitivity_plot(plot_dir: Path, dataset: str) -> None:\n    metrics_df = pd.read_csv(plot_dir / \"metrics.csv\")\n    sns.scatterplot(\n        metrics_df,\n        x=\"Explanation Sensitivity\",\n        y=\"Explanation Equivariance\",\n        hue=\"Explanation\",\n        alpha=0.5,\n        s=10,\n    )\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(plot_dir / f\"sensitivity_comparison_{dataset}.pdf\")\n    plt.close()\n\n\ndef draw_molecule(g, edge_mask=None, draw_edge_labels=False):\n    g = g.copy().to_undirected()\n    node_labels = {}\n    for u, data in g.nodes(data=True):\n        node_labels[u] = data[\"name\"]\n    pos = nx.planar_layout(g)\n    pos = nx.spring_layout(g, pos=pos)\n    if edge_mask is None:\n        edge_color = \"black\"\n        widths = None\n    else:\n        edge_color = [edge_mask[(u, v)] for u, v in g.edges()]\n        widths = [x * 10 for x in edge_color]\n    nx.draw(\n        g,\n        pos=pos,\n        labels=node_labels,\n        width=widths,\n        edge_color=edge_color,\n        edge_cmap=plt.cm.Blues,\n        node_color=\"azure\",\n    )\n\n    if draw_edge_labels and edge_mask is not None:\n        edge_labels = {k: (\"%.2f\" % v) for k, v in edge_mask.items()}\n        nx.draw_networkx_edge_labels(g, pos, edge_labels=edge_labels, font_color=\"red\")\n    plt.show()\n\n\ndef wrap_labels(ax, width, break_long_words=False, do_y: bool = False) -> None:\n    \"\"\"\n    Break labels in several lines in a figure\n    Args:\n        ax: figure axes\n        width: maximal number of characters per line\n        break_long_words: if True, allow breaks in the middle of a word\n        do_y: if True, apply the function to the y axis as well\n    Returns:\n    \"\"\"\n    labels = []\n    for label in ax.get_xticklabels():\n        text = label.get_text()\n        labels.append(\n            textwrap.fill(text, width=width, break_long_words=break_long_words)\n        )\n    ax.set_xticklabels(labels, rotation=0)\n    if do_y:\n        labels = []\n        for label in ax.get_yticklabels():\n            text = label.get_text()\n            labels.append(\n                textwrap.fill(text, width=width, break_long_words=break_long_words)\n            )\n        ax.set_yticklabels(labels, rotation=0)\n\n\ndef global_relax_invariance() -> None:\n    sns.set(font_scale=1.2)\n    sns.set_style(\"whitegrid\")\n    with open(Path.cwd() / \"results_dir.json\") as f:\n        path_dic = json.load(f)\n    global_df = []\n    for dataset, experiment_name in itertools.product(\n        [\"ECG\", \"Fa.MNIST\"],\n        [\"feature_importance\", \"example_importance\", \"concept_importance\"],\n    ):\n        dataset_df = pd.read_csv(\n            Path.cwd() / path_dic[dataset] / experiment_name / \"metrics.csv\"\n        )\n        dataset_df[\"Dataset\"] = [dataset] * len(dataset_df)\n        dataset_df[\"Experiment\"] = [experiment_name] * len(dataset_df)\n        dataset_df = dataset_df.drop(\n            dataset_df[\n                (dataset_df.Explanation == \"SimplEx-Conv3\")\n                | (dataset_df.Explanation == \"Representation Similarity-Conv3\")\n                | (dataset_df.Explanation == \"CAR-Conv3\")\n                | (dataset_df.Explanation == \"CAV-Conv3\")\n            ].index\n        )\n        rename_dic = {\"Representation Similarity-Lin1\": \"Rep. Similar-Lin1\"}\n        dataset_df = dataset_df.replace(rename_dic)\n        global_df.append(dataset_df)\n    global_df = pd.concat(global_df)\n\n    n_datasets = len(global_df[\"Dataset\"].unique())\n\n    # Create a grid of plots\n    fig, axs = plt.subplots(nrows=n_datasets, ncols=3, figsize=(17, 9), sharex=True)\n\n    datasets = global_df[\"Dataset\"].unique()\n    y_titles = [\n        \"Feature Importance Equivariance\",\n        \"Example Importance Invariance\",\n        \"Concept Importance Invariance\",\n    ]\n    experiments = global_df[\"Experiment\"].unique()\n    style_handles = []\n    style_labels = []\n    # Loop over the subplots and plot the data\n    for i, dataset in enumerate(datasets):  # rows\n        for j, experiment in enumerate(experiments):  # columns\n            ax = axs[i, j]\n            metrics_df = global_df[\n                (global_df[\"Dataset\"] == dataset)\n                & (global_df[\"Experiment\"] == experiment)\n            ]\n            y = (\n                \"Explanation Equivariance\"\n                if \"feature\" in experiment\n                else \"Explanation Invariance\"\n            )\n            plot_df = metrics_df.groupby([\"Model Type\", \"Explanation\"]).mean(\n                numeric_only=True\n            )\n            plot_df[[\"Model Invariance CI\", f\"{y} CI\"]] = 2 * metrics_df.groupby(\n                [\"Model Type\", \"Explanation\"]\n            )[[\"Model Invariance\", y]].apply(\"sem\")\n            sns.scatterplot(\n                ax=ax,\n                data=plot_df,\n                x=\"Model Invariance\",\n                y=y,\n                hue=\"Model Type\",\n                edgecolor=\"black\",\n                alpha=0.5,\n                style=\"Explanation\",\n                markers=markers,\n                s=200,\n            )\n            ax.errorbar(\n                x=plot_df[\"Model Invariance\"],\n                y=plot_df[y],\n                xerr=plot_df[\"Model Invariance CI\"],\n                yerr=plot_df[f\"{y} CI\"],\n                ecolor=\"black\",\n                elinewidth=1.7,\n                linestyle=\"\",\n                capsize=1.7,\n                capthick=1.7,\n            )\n            ax.set_xscale(\"linear\")\n            ax.axline((0, 0), slope=1, color=\"gray\", linestyle=\"dotted\")\n            ax.set_xlim(0, 1.1)\n            ax.set_ylim(0, 1.1)\n            ax.set_ylabel(y_titles[j])\n            # Get handles and labels for hue and style legends\n            handles, labels = ax.get_legend_handles_labels()\n            explanation_cut = labels.index(\"Explanation\") + int(j > 0)\n            # Create separate legends for hue and style\n            if i == 0 and j == 0:\n                hue_handles = handles[\n                    :explanation_cut\n                ]  # first half of handles are for hue\n                hue_labels = labels[:explanation_cut]\n            if i == len(datasets) - 1:\n                style_handles.extend(handles[explanation_cut:])\n                style_labels.extend(labels[explanation_cut:])\n\n            ax.legend().remove()\n            if j == 1:\n                ax.set_title(dataset)\n    fig.legend(\n        hue_handles + style_handles,\n        hue_labels + style_labels,\n        loc=\"lower center\",\n        ncol=5,\n        bbox_to_anchor=(0.5, -0.1),\n    )\n    # fig.tight_layout()\n\n    plt.savefig(\n        Path.cwd() / f\"results/global_relax_invariance.pdf\", bbox_inches=\"tight\"\n    )\n    plt.close()\n\n\ndef training_dynamic_plot(\n    data_path: Path = Path.cwd() / \"results/d8-wideresnet-training_dynamics.csv\",\n) -> None:\n    sns.set(font_scale=1.0)\n    sns.set_style(\"whitegrid\")\n    df = pd.read_csv(data_path)\n    df = df[\n        [\n            \"epoch\",\n            \"cifar100_d8_wideresnet_seed42 - model_invariance\",\n            \"stl10_d8_wideresnet_seed42 - model_invariance\",\n            \"cifar100_d8_wideresnet_seed42 - gradient_equivariance\",\n            \"stl10_d8_wideresnet_seed42 - gradient_equivariance\",\n        ]\n    ]\n    rename_cols = {\n        \"epoch\": \"Epoch\",\n        \"cifar100_d8_wideresnet_seed42 - model_invariance\": \"CIFAR100 Model Invariance\",\n        \"stl10_d8_wideresnet_seed42 - model_invariance\": \"STL10 Model Invariance\",\n        \"cifar100_d8_wideresnet_seed42 - gradient_equivariance\": \"CIFAR100 Gradient Equivariance\",\n        \"stl10_d8_wideresnet_seed42 - gradient_equivariance\": \"STL10 Gradient Equivariance\",\n    }\n    df = df.rename(columns=rename_cols)\n    data = []\n    for dataset in [\"CIFAR100\", \"STL10\"]:\n        for property in [\"Model Invariance\", \"Gradient Equivariance\"]:\n            for epoch, score in df[[\"Epoch\", f\"{dataset} {property}\"]].values:\n                data.append(\n                    {\n                        \"Dataset\": dataset,\n                        \"Property\": property,\n                        \"Epoch\": epoch,\n                        \"Score\": score,\n                    }\n                )\n\n    plot_df = pd.DataFrame(data)\n    sns.lineplot(data=plot_df, x=\"Epoch\", y=\"Score\", hue=\"Dataset\", style=\"Property\")\n    plt.savefig(Path.cwd() / \"results/training_dynamics.pdf\", bbox_inches=\"tight\")\n\n\n# if __name__ == \"__main__\":\n#     logging.basicConfig(\n#         level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n#     )\n#     parser = argparse.ArgumentParser()\n#     parser.add_argument(\"--experiment_name\", type=str, default=\"feature_importance\")\n#     parser.add_argument(\"--plot_name\", type=str, default=\"relax_invariance\")\n#     parser.add_argument(\"--dataset\", type=str, default=\"ecg\")\n#     parser.add_argument(\"--model\", type=str, default=\"cnn32_seed42\")\n#     parser.add_argument(\"--concept\", type=str, default=None)\n#     args = parser.parse_args()\n#     with open(Path.cwd() / \"results_dir.json\") as f:\n#         path_dic = json.load(f)\n#     dataset_full_names = {\n#         \"ecg\": \"ECG\",\n#         \"mut\": \"Muta.\",\n#         \"mnet\": \"M.Net40\",\n#         \"fashion_mnist\": \"Fa.MNIST\",\n#     }\n#     plot_path = (\n#         (Path.cwd() / path_dic[dataset_full_names[args.dataset]] / args.experiment_name)\n#         if \"global\" not in args.plot_name and args.plot_name != \"training_dynamics\"\n#         else Path.cwd() / \"results\"\n#     )\n\n#     logging.info(f\"Saving {args.plot_name} plot in {str(plot_path)}\")\n#     match args.plot_name:\n#         case \"robustness\":\n#             single_robustness_plots(plot_path, args.dataset, args.experiment_name)\n#         case \"global_robustness\":\n#             global_robustness_plots(args.experiment_name)\n#         case \"relax_invariance\":\n#             relaxing_invariance_plots(plot_path, args.dataset, args.experiment_name)\n#         case \"mc_convergence\":\n#             mc_convergence_plot(plot_path, args.dataset, args.experiment_name)\n#         case \"enforce_invariance\":\n#             enforce_invariance_plot(plot_path, args.dataset)\n#         case \"sensitivity_comparison\":\n#             sensitivity_plot(plot_path, args.dataset)\n#         case \"global_relax_invariance\":\n#             global_relax_invariance()\n#         case \"training_dynamics\":\n#             training_dynamic_plot()\n#         case other:\n#             raise ValueError(\"Unknown plot name\")\n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-10-03T13:14:23.847803Z","iopub.status.idle":"2024-10-03T13:14:23.848352Z","shell.execute_reply.started":"2024-10-03T13:14:23.848079Z","shell.execute_reply":"2024-10-03T13:14:23.848104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Path.cwd()","metadata":{"_uuid":"5d6a4442-ca62-4c30-9c6c-536484477901","_cell_guid":"d47c25f5-f561-4ac1-a485-8d08d893335b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ecg main","metadata":{}},{"cell_type":"code","source":"\ndef train_ecg_model(\n    random_seed: int,\n    latent_dim: int,\n    batch_size: int,\n    model_name: str = \"model\",\n    model_dir: Path = Path.cwd() / f\"results/ecg/\",\n#     data_dir: Path = Path.cwd() / \"datasets/ecg\",\n    data_dir: Path = Path('../input/heartbeat'),\n) -> None:\n    logging.info(\"Fitting the ECG classifiers\")\n    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n    set_random_seed(random_seed)\n    model_dir = model_dir / model_name\n    if not model_dir.exists():\n        os.makedirs(model_dir)\n    models = {\n        \"All-CNN\": AllCNN(latent_dim, f\"{model_name}_allcnn\"),\n        \"Standard-CNN\": StandardCNN(latent_dim, f\"{model_name}_standard\"),\n        \"Augmented-CNN\": StandardCNN(latent_dim, f\"{model_name}_augmented\"),\n    }\n    train_set = ECGDataset(data_dir, train=True, balance_dataset=True)\n    test_set = ECGDataset(data_dir, train=False, balance_dataset=False)\n    train_loader = DataLoader(train_set, batch_size, shuffle=True)\n    test_loader = DataLoader(test_set, batch_size, shuffle=True)\n    for model_type in models:\n        logging.info(f\"Now fitting a {model_type} classifier\")\n        if model_type == \"Augmented-CNN\":\n            models[model_type].fit(\n                device,\n                train_loader,\n                test_loader,\n                model_dir,\n                augmentation=True,\n                checkpoint_interval=10,\n            )\n        else:\n            models[model_type].fit(\n                device,\n                train_loader,\n                test_loader,\n                model_dir,\n                augmentation=False,\n                checkpoint_interval=10,\n            )\n\ndef feature_importance(\n    random_seed: int,\n    latent_dim: int,\n    batch_size: int,\n    plot: bool,\n    model_name: str = \"model\",\n    model_dir: Path = Path.cwd() / f\"results/ecg/\",\n#   data_dir: Path = Path.cwd() / \"datasets/ecg\",\n    data_dir: Path = Path('../input/heartbeat'),\n    n_test: int = 1000,\n) -> None:\n    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n    set_random_seed(random_seed)\n    test_set = ECGDataset(data_dir, train=False, balance_dataset=False)\n#     print(test_set)\n    test_subset = Subset(test_set, torch.randperm(len(test_set))[:n_test])\n    test_loader = DataLoader(test_subset, batch_size)\n    models = {\n        \"All-CNN\": AllCNN(latent_dim, f\"{model_name}_allcnn\"),\n        \"Standard-CNN\": StandardCNN(latent_dim, f\"{model_name}_standard\"),\n        \"Augmented-CNN\": StandardCNN(latent_dim, f\"{model_name}_augmented\"),\n    }\n    attr_methods = {\n        \"DeepLift\": DeepLift,\n        \"Integrated Gradients\": IntegratedGradients,\n        \"Gradient Shap\": GradientShap,\n        \"Feature Permutation\": FeaturePermutation,\n        \"Feature Ablation\": FeatureAblation,\n        \"Feature Occlusion\": Occlusion,\n    }\n    model_dir = model_dir / model_name\n    save_dir = model_dir / \"feature_importance\"\n    if not save_dir.exists():\n        os.makedirs(save_dir)\n    translation = Translation1D()\n    metrics = []\n    for model_type in models:\n        logging.info(f\"Now working with {model_type} classifier\")\n        model = models[model_type]\n        model.load_metadata(model_dir)\n        model.load_state_dict(torch.load(model_dir / f\"{model.name}.pt\"), strict=False)\n        model.to(device).eval()\n        model_inv = model_invariance_exact(model, translation, test_loader, device)\n        logging.info(f\"Model invariance: {torch.mean(model_inv):.3g}\")\n        for attr_name in attr_methods:\n            logging.info(f\"Now working with {attr_name} explainer\")\n            feat_importance = FeatureImportance(attr_methods[attr_name](model))\n            explanation_equiv = explanation_equivariance_exact(\n                feat_importance, translation, test_loader, device\n            )\n            for inv, equiv in zip(model_inv, explanation_equiv):\n                metrics.append([model_type, attr_name, inv.item(), equiv.item()])\n            logging.info(\n                f\"Explanation equivariance: {torch.mean(explanation_equiv):.3g}\"\n            )\n    metrics_df = pd.DataFrame(\n        data=metrics,\n        columns=[\n            \"Model Type\",\n            \"Explanation\",\n            \"Model Invariance\",\n            \"Explanation Equivariance\",\n        ],\n    )\n    metrics_df.to_csv(save_dir / \"metrics.csv\", index=False)\n    if plot:\n        single_robustness_plots(save_dir, \"ecg\", \"feature_importance\")\n        # save_dir = Path(\"E:/RobustXAI-main/results/ecg/cnn32_seed42/feature_importance\")\n        relaxing_invariance_plots(save_dir, \"ecg\", \"feature_importance\")\n        \ndef example_importance(\n    random_seed: int,\n    latent_dim: int,\n    batch_size: int,\n    plot: bool,\n    model_name: str = \"model\",\n#     model_dir: Path = Path.cwd() / f\"results/ecg/\",\n    model_dir: Path = Path(\"/kaggle/inputs/robustxai-real/results/ecg/\"),\n#     data_dir: Path = Path.cwd() / \"datasets/ecg\",\n    data_dir: Path = Path('../input/heartbeat'),\n    n_test: int = 1000,\n    n_train: int = 100,\n    recursion_depth: int = 100,\n) -> None:\n    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n    set_random_seed(random_seed)\n    train_set = ECGDataset(data_dir, train=True, balance_dataset=False)\n    train_loader = DataLoader(train_set, n_train, shuffle=True)\n    X_train, Y_train = next(iter(train_loader))\n    X_train, Y_train = X_train.to(device), Y_train.to(device)\n    train_sampler = RandomSampler(\n        train_set, replacement=True, num_samples=recursion_depth * batch_size\n    )\n    train_loader_replacement = DataLoader(train_set, batch_size, sampler=train_sampler)\n    test_set = ECGDataset(data_dir, train=False, balance_dataset=False)\n    test_subset = Subset(test_set, torch.randperm(len(test_set))[:n_test])\n    test_loader = DataLoader(test_subset, batch_size)\n    models = {\n        \"All-CNN\": AllCNN(latent_dim, f\"{model_name}_allcnn\"),\n        \"Standard-CNN\": StandardCNN(latent_dim, f\"{model_name}_standard\"),\n        \"Augmented-CNN\": StandardCNN(latent_dim, f\"{model_name}_augmented\"),\n    }\n    attr_methods = {\n        \"SimplEx\": SimplEx,\n        \"Representation Similarity\": RepresentationSimilarity,\n        \"TracIn\": TracIn,\n        \"Influence Functions\": InfluenceFunctions,\n    }\n    model_dir = model_dir / model_name\n    save_dir = model_dir / \"example_importance\"\n    if not save_dir.exists():\n        os.makedirs(save_dir)\n    translation = Translation1D()\n    metrics = []\n    for model_type in models:\n        logging.info(f\"Now working with {model_type} classifier\")\n        model = models[model_type]\n        model.load_metadata(model_dir)\n        model.load_state_dict(torch.load(model_dir / f\"{model.name}.pt\"), strict=False)\n        model.to(device).eval()\n        model_inv = model_invariance_exact(model, translation, test_loader, device)\n        logging.info(f\"Model invariance: {torch.mean(model_inv):.3g}\")\n        model_layers = {\"Lin1\": model.fc1, \"Conv3\": model.cnn3}\n        for attr_name in attr_methods:\n            logging.info(f\"Now working with {attr_name} explainer\")\n            model.load_state_dict(\n                torch.load(model_dir / f\"{model.name}.pt\"), strict=False\n            )\n            if attr_name in {\"TracIn\", \"Influence Functions\"}:\n                ex_importance = attr_methods[attr_name](\n                    model,\n                    X_train,\n                    Y_train=Y_train,\n                    train_loader=train_loader_replacement,\n                    loss_function=nn.CrossEntropyLoss(),\n                    save_dir=save_dir / model.name,\n                    recursion_depth=recursion_depth,\n                )\n                explanation_inv = explanation_invariance_exact(\n                    ex_importance, translation, test_loader, device\n                )\n                for inv_model, inv_expl in zip(model_inv, explanation_inv):\n                    metrics.append(\n                        [model_type, attr_name, inv_model.item(), inv_expl.item()]\n                    )\n                logging.info(\n                    f\"Explanation invariance: {torch.mean(explanation_inv):.3g}\"\n                )\n            else:\n                for layer_name in model_layers:\n                    ex_importance = attr_methods[attr_name](\n                        model, X_train, Y_train=Y_train, layer=model_layers[layer_name]\n                    )\n                    explanation_inv = explanation_invariance_exact(\n                        ex_importance, translation, test_loader, device\n                    )\n                    ex_importance.remove_hook()\n                    for inv_model, inv_expl in zip(model_inv, explanation_inv):\n                        metrics.append(\n                            [\n                                model_type,\n                                f\"{attr_name}-{layer_name}\",\n                                inv_model.item(),\n                                inv_expl.item(),\n                            ]\n                        )\n                    logging.info(\n                        f\"Explanation invariance for {layer_name}: {torch.mean(explanation_inv):.3g}\"\n                    )\n    metrics_df = pd.DataFrame(\n        data=metrics,\n        columns=[\n            \"Model Type\",\n            \"Explanation\",\n            \"Model Invariance\",\n            \"Explanation Invariance\",\n        ],\n    )\n    metrics_df.to_csv(save_dir / \"metrics.csv\", index=False)\n    if plot:\n        single_robustness_plots(save_dir, \"ecg\", \"example_importance\")\n        relaxing_invariance_plots(save_dir, \"ecg\", \"example_importance\")\n\n\ndef concept_importance(\n    random_seed: int,\n    latent_dim: int,\n    batch_size: int,\n    plot: bool,\n    model_name: str = \"model\",\n    model_dir: Path = Path.cwd() / f\"results/ecg/\",\n#     data_dir: Path = Path.cwd() / \"datasets/ecg\",\n    data_dir: Path = Path('../input/heartbeat'),\n    n_test: int = 1000,\n    concept_set_size: int = 100,\n) -> None:\n    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n    set_random_seed(random_seed)\n    train_set = ECGDataset(\n        data_dir, train=True, binarize_label=False, balance_dataset=False\n    )\n    test_set = ECGDataset(\n        data_dir, train=False, balance_dataset=False, binarize_label=False\n    )\n    test_subset = Subset(test_set, torch.randperm(len(test_set))[:n_test])\n    test_loader = DataLoader(test_subset, batch_size)\n    models = {\n        \"All-CNN\": AllCNN(latent_dim, f\"{model_name}_allcnn\"),\n        \"Standard-CNN\": StandardCNN(latent_dim, f\"{model_name}_standard\"),\n        \"Augmented-CNN\": StandardCNN(latent_dim, f\"{model_name}_augmented\"),\n    }\n    attr_methods = {\"CAV\": CAV, \"CAR\": CAR}\n    model_dir = model_dir / model_name\n    save_dir = model_dir / \"concept_importance\"\n    if not save_dir.exists():\n        os.makedirs(save_dir)\n    translation = Translation1D()\n    metrics = []\n    for model_type in models:\n        logging.info(f\"Now working with {model_type} classifier\")\n        model = models[model_type]\n        model.load_metadata(model_dir)\n        model.load_state_dict(torch.load(model_dir / f\"{model.name}.pt\"), strict=False)\n        model.to(device).eval()\n        model_inv = model_invariance_exact(model, translation, test_loader, device)\n        logging.info(f\"Model invariance: {torch.mean(model_inv):.3g}\")\n        model_layers = {\"Lin1\": model.fc1, \"Conv3\": model.cnn3}\n        for layer_name, attr_name in itertools.product(model_layers, attr_methods):\n            logging.info(\n                f\"Now working with {attr_name} explainer on layer {layer_name}\"\n            )\n            conc_importance = attr_methods[attr_name](\n                model, train_set, n_classes=2, layer=model_layers[layer_name]\n            )\n            conc_importance.fit(device, concept_set_size)\n            concept_acc = conc_importance.concept_accuracy(\n                test_set, device, concept_set_size=concept_set_size\n            )\n            for concept_name in concept_acc:\n                logging.info(\n                    f\"Concept {concept_name} accuracy: {concept_acc[concept_name]:.2g}\"\n                )\n            explanation_inv = explanation_invariance_exact(\n                conc_importance, translation, test_loader, device, similarity=accuracy\n            )\n            conc_importance.remove_hook()\n            for inv_model, inv_expl in zip(model_inv, explanation_inv):\n                metrics.append(\n                    [\n                        model_type,\n                        f\"{attr_name}-{layer_name}\",\n                        inv_model.item(),\n                        inv_expl.item(),\n                    ]\n                )\n            logging.info(f\"Explanation invariance: {torch.mean(explanation_inv):.3g}\")\n    metrics_df = pd.DataFrame(\n        data=metrics,\n        columns=[\n            \"Model Type\",\n            \"Explanation\",\n            \"Model Invariance\",\n            \"Explanation Invariance\",\n        ],\n    )\n    metrics_df.to_csv(save_dir / \"metrics.csv\", index=False)\n    if plot:\n        single_robustness_plots(save_dir, \"ecg\", \"concept_importance\")\n        relaxing_invariance_plots(save_dir, \"ecg\", \"concept_importance\")\n\n\ndef enforce_invariance(\n    random_seed: int,\n    latent_dim: int,\n    batch_size: int,\n    plot: bool,\n    model_name: str = \"model\",\n    model_dir: Path = Path.cwd() / f\"results/ecg/\",\n#     data_dir: Path = Path.cwd() / \"datasets/ecg\",\n    data_dir: Path = Path('../input/heartbeat'),\n    n_test: int = 1000,\n    concept_set_size: int = 100,\n) -> None:\n    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n    set_random_seed(random_seed)\n    train_set = ECGDataset(\n        data_dir, train=True, binarize_label=False, balance_dataset=False\n    )\n    test_set = ECGDataset(data_dir, train=False, balance_dataset=False)\n    test_subset = Subset(test_set, torch.randperm(len(test_set))[:n_test])\n    test_loader = DataLoader(test_subset, batch_size)\n    models = {\"All-CNN\": AllCNN(latent_dim, f\"{model_name}_allcnn\")}\n    attr_methods = {\"CAV\": CAV, \"CAR\": CAR}\n    model_dir = model_dir / model_name\n    save_dir = model_dir / \"enforce_invariance\"\n    if not save_dir.exists():\n        os.makedirs(save_dir)\n    translation = Translation1D()\n    metrics = []\n    for model_type in models:\n        logging.info(f\"Now working with {model_type} classifier\")\n        model = models[model_type]\n        model.load_metadata(model_dir)\n        model.load_state_dict(torch.load(model_dir / f\"{model.name}.pt\"), strict=False)\n        model.to(device).eval()\n        model_inv = model_invariance_exact(model, translation, test_loader, device)\n        logging.info(f\"Model invariance: {torch.mean(model_inv):.3g}\")\n        for attr_name in attr_methods:\n            logging.info(f\"Now working with {attr_name} explainer\")\n            attr_method = attr_methods[attr_name](\n                model, train_set, n_classes=2, layer=model.cnn3\n            )\n            if isinstance(attr_method, ConceptExplainer):\n                attr_method.fit(device, concept_set_size)\n            for N_inv in [1, 5, 20, 50, 100, 187]:\n                logging.info(\n                    f\"Now working with invariant explainer with N_inv = {N_inv}\"\n                )\n                inv_method = InvariantExplainer(\n                    attr_method,\n                    translation,\n                    N_inv,\n                    isinstance(attr_method, ConceptExplainer),\n                )\n                explanation_inv = explanation_invariance_exact(\n                    inv_method, translation, test_loader, device, similarity=accuracy\n                )\n                logging.info(\n                    f\"N_inv = {N_inv} - Explanation invariance = {torch.mean(explanation_inv):.3g}\"\n                )\n                for inv_expl in explanation_inv:\n                    metrics.append(\n                        [model_type, f\"{attr_name}-Equiv\", N_inv, inv_expl.item()]\n                    )\n    metrics_df = pd.DataFrame(\n        data=metrics,\n        columns=[\"Model Type\", \"Explanation\", \"N_inv\", \"Explanation Invariance\"],\n    )\n    metrics_df.to_csv(save_dir / \"metrics.csv\", index=False)\n    if plot:\n        enforce_invariance_plot(save_dir, \"ecg\")\n\n\ndef sensitivity_comparison(\n    random_seed: int,\n    latent_dim: int,\n    batch_size: int,\n    plot: bool,\n    model_name: str = \"model\",\n    model_dir: Path = Path.cwd() / f\"results/ecg/\",\n#     data_dir: Path = Path.cwd() / \"datasets/ecg\",\n    data_dir: Path = Path('../input/heartbeat'),\n    n_test: int = 1000,\n) -> None:\n    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n    set_random_seed(random_seed)\n    test_set = ECGDataset(data_dir, train=False, balance_dataset=False)\n    test_subset = Subset(test_set, torch.randperm(len(test_set))[:n_test])\n    test_loader = DataLoader(test_subset, batch_size)\n    models = {\"Augmented-CNN\": StandardCNN(latent_dim, f\"{model_name}_augmented\")}\n    attr_methods = {\n        \"Integrated Gradients\": IntegratedGradients,\n        \"Gradient Shap\": GradientShap,\n        \"Feature Permutation\": FeaturePermutation,\n        \"Feature Ablation\": FeatureAblation,\n        \"Feature Occlusion\": Occlusion,\n    }\n    model_dir = model_dir / model_name\n    save_dir = model_dir / \"sensitivity\"\n    if not save_dir.exists():\n        os.makedirs(save_dir)\n    translation = Translation1D()\n    metrics = []\n    for model_type in models:\n        logging.info(f\"Now working with {model_type} classifier\")\n        model = models[model_type]\n        model.load_metadata(model_dir)\n        model.load_state_dict(torch.load(model_dir / f\"{model.name}.pt\"), strict=False)\n        model.to(device).eval()\n        for attr_name in attr_methods:\n            logging.info(f\"Now working with {attr_name} explainer\")\n            attr_method = attr_methods[attr_name](model)\n            feat_importance = FeatureImportance(attr_method)\n            explanation_sens = (\n                sensitivity(attr_method, test_loader, device).cpu().numpy()\n            )\n            explanation_equiv = (\n                explanation_equivariance_exact(\n                    feat_importance, translation, test_loader, device\n                )\n                .cpu()\n                .numpy()\n            )\n            corr = np.corrcoef(explanation_sens, explanation_equiv)\n            logging.info(f\"Metrics correlation: {corr[0, 1].item():.3g}\")\n            for sens, equiv in zip(explanation_sens, explanation_equiv):\n                metrics.append([model_type, attr_name, sens, equiv])\n    metrics_df = pd.DataFrame(\n        data=metrics,\n        columns=[\n            \"Model Type\",\n            \"Explanation\",\n            \"Explanation Sensitivity\",\n            \"Explanation Equivariance\",\n        ],\n    )\n    metrics_df.to_csv(save_dir / \"metrics.csv\", index=False)\n    if plot:\n        sensitivity_plot(save_dir, \"ecg\")","metadata":{"_uuid":"e03ae4f2-e220-4d78-9970-6824135bc57d","_cell_guid":"87432825-0d57-430f-93c2-453e9d9093a4","execution":{"iopub.status.busy":"2024-10-03T13:14:40.327848Z","iopub.execute_input":"2024-10-03T13:14:40.328325Z","iopub.status.idle":"2024-10-03T13:14:40.412776Z","shell.execute_reply.started":"2024-10-03T13:14:40.328265Z","shell.execute_reply":"2024-10-03T13:14:40.411556Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(Path.cwd())","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:17:44.003539Z","iopub.execute_input":"2024-10-03T13:17:44.004017Z","iopub.status.idle":"2024-10-03T13:17:44.011464Z","shell.execute_reply.started":"2024-10-03T13:17:44.003973Z","shell.execute_reply":"2024-10-03T13:17:44.010238Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"/kaggle/input/robustxai-real/results/ecg/cnn32_seed42\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:18:22.778281Z","iopub.execute_input":"2024-10-03T13:18:22.778795Z","iopub.status.idle":"2024-10-03T13:18:23.968748Z","shell.execute_reply.started":"2024-10-03T13:18:22.778750Z","shell.execute_reply":"2024-10-03T13:18:23.967384Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"cnn32_seed42_allcnn.json\t       cnn32_seed42_augmented_checkpoint5.pt\ncnn32_seed42_allcnn.pt\t\t       cnn32_seed42_augmented_checkpoint6.pt\ncnn32_seed42_allcnn_checkpoint1.pt     cnn32_seed42_augmented_checkpoint7.pt\ncnn32_seed42_allcnn_checkpoint10.pt    cnn32_seed42_augmented_checkpoint8.pt\ncnn32_seed42_allcnn_checkpoint11.pt    cnn32_seed42_standard.json\ncnn32_seed42_allcnn_checkpoint2.pt     cnn32_seed42_standard.pt\ncnn32_seed42_allcnn_checkpoint3.pt     cnn32_seed42_standard_checkpoint1.pt\ncnn32_seed42_allcnn_checkpoint4.pt     cnn32_seed42_standard_checkpoint10.pt\ncnn32_seed42_allcnn_checkpoint5.pt     cnn32_seed42_standard_checkpoint11.pt\ncnn32_seed42_allcnn_checkpoint6.pt     cnn32_seed42_standard_checkpoint12.pt\ncnn32_seed42_allcnn_checkpoint7.pt     cnn32_seed42_standard_checkpoint2.pt\ncnn32_seed42_allcnn_checkpoint8.pt     cnn32_seed42_standard_checkpoint3.pt\ncnn32_seed42_allcnn_checkpoint9.pt     cnn32_seed42_standard_checkpoint4.pt\ncnn32_seed42_augmented.json\t       cnn32_seed42_standard_checkpoint5.pt\ncnn32_seed42_augmented.pt\t       cnn32_seed42_standard_checkpoint6.pt\ncnn32_seed42_augmented_checkpoint1.pt  cnn32_seed42_standard_checkpoint7.pt\ncnn32_seed42_augmented_checkpoint2.pt  cnn32_seed42_standard_checkpoint8.pt\ncnn32_seed42_augmented_checkpoint3.pt  cnn32_seed42_standard_checkpoint9.pt\ncnn32_seed42_augmented_checkpoint4.pt  feature_importance\n","output_type":"stream"}]},{"cell_type":"code","source":"os.chdir('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:19:10.582615Z","iopub.execute_input":"2024-10-03T13:19:10.584023Z","iopub.status.idle":"2024-10-03T13:19:10.590318Z","shell.execute_reply.started":"2024-10-03T13:19:10.583969Z","shell.execute_reply":"2024-10-03T13:19:10.588873Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:19:14.244667Z","iopub.execute_input":"2024-10-03T13:19:14.245154Z","iopub.status.idle":"2024-10-03T13:19:15.421214Z","shell.execute_reply.started":"2024-10-03T13:19:14.245109Z","shell.execute_reply":"2024-10-03T13:19:15.419788Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"!cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-10-03T13:18:16.479607Z","iopub.execute_input":"2024-10-03T13:18:16.480069Z","iopub.status.idle":"2024-10-03T13:18:17.653801Z","shell.execute_reply.started":"2024-10-03T13:18:16.480025Z","shell.execute_reply":"2024-10-03T13:18:17.652018Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# !pip install networkx","metadata":{"execution":{"iopub.status.busy":"2024-10-03T06:44:21.837919Z","iopub.execute_input":"2024-10-03T06:44:21.838394Z","iopub.status.idle":"2024-10-03T06:44:33.216409Z","shell.execute_reply.started":"2024-10-03T06:44:21.838354Z","shell.execute_reply":"2024-10-03T06:44:33.215185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport argparse\n\nlogging.basicConfig(\n        level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n    )\n# sys.argv = sys.argv[:1]\n# parser = argparse.ArgumentParser()\n# parser.add_argument(\"--name\", type=str, default=\"feature_importance\")\n# parser.add_argument(\"--seed\", type=int, default=42)\n# parser.add_argument(\"--batch_size\", type=int, default=500)\n# parser.add_argument(\"--latent_dim\", type=int, default=32)\n# parser.add_argument(\"--train\", action=\"store_true\")\n# parser.add_argument(\"--plot\", action=\"store_true\")\n# parser.add_argument(\"--n_test\", type=int, default=1000)\n# args = parser.parse_args()\n\nclass Args:\n    def __init__(self):\n        self.name = \"feature_importance\"\n        self.seed = 42\n        self.batch_size = 500\n        self.latent_dim = 32\n        self.train = False  # 默认值为 False\n        self.plot = True   # 默认值为 False\n        self.n_test = 1000\n\nargs = Args()\nargs.train = True\n\nprint(args.train)","metadata":{"_uuid":"30a33389-6de4-4b35-b6ef-38a57fa9637b","_cell_guid":"cd1163ac-0331-4759-a5bb-9513e91179a5","execution":{"iopub.status.busy":"2024-10-03T11:02:12.513944Z","iopub.execute_input":"2024-10-03T11:02:12.514700Z","iopub.status.idle":"2024-10-03T11:02:12.521697Z","shell.execute_reply.started":"2024-10-03T11:02:12.514662Z","shell.execute_reply":"2024-10-03T11:02:12.520740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = f\"cnn{args.latent_dim}_seed{args.seed}\"\nif args.train:\n    train_ecg_model(\n        args.seed, args.latent_dim, args.batch_size, model_name=model_name\n    )","metadata":{"execution":{"iopub.status.busy":"2024-10-03T11:02:14.263818Z","iopub.execute_input":"2024-10-03T11:02:14.264231Z","iopub.status.idle":"2024-10-03T11:21:10.253816Z","shell.execute_reply.started":"2024-10-03T11:02:14.264189Z","shell.execute_reply":"2024-10-03T11:21:10.252884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### feature_importance","metadata":{}},{"cell_type":"code","source":"print(args.name)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T11:21:10.255906Z","iopub.execute_input":"2024-10-03T11:21:10.256364Z","iopub.status.idle":"2024-10-03T11:21:10.261495Z","shell.execute_reply.started":"2024-10-03T11:21:10.256319Z","shell.execute_reply":"2024-10-03T11:21:10.260627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if args.name == \"feature_importance\":\n    feature_importance(\n        args.seed,\n        args.latent_dim,\n        args.batch_size,\n        args.plot,\n        model_name,\n        n_test=args.n_test,\n    )","metadata":{"_uuid":"6677215d-5b10-4adc-bd65-6ab4cc2dbcd5","_cell_guid":"a9e1028e-fca3-4531-be48-265a43a15365","execution":{"iopub.status.busy":"2024-10-03T11:21:10.262924Z","iopub.execute_input":"2024-10-03T11:21:10.263564Z","iopub.status.idle":"2024-10-03T12:14:55.473876Z","shell.execute_reply.started":"2024-10-03T11:21:10.263516Z","shell.execute_reply":"2024-10-03T12:14:55.473051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### example_importance","metadata":{}},{"cell_type":"code","source":"args.name = \"example_importance\"\nprint(args.name)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T12:48:48.469488Z","iopub.execute_input":"2024-10-03T12:48:48.469893Z","iopub.status.idle":"2024-10-03T12:48:48.475021Z","shell.execute_reply.started":"2024-10-03T12:48:48.469854Z","shell.execute_reply":"2024-10-03T12:48:48.474011Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"example_importance\n","output_type":"stream"}]},{"cell_type":"code","source":"example_importance(\n                args.seed,\n                args.latent_dim,\n                args.batch_size,\n                args.plot,\n                model_name,\n                n_test=args.n_test,\n            )","metadata":{"execution":{"iopub.status.busy":"2024-10-03T12:48:50.350796Z","iopub.execute_input":"2024-10-03T12:48:50.351494Z","iopub.status.idle":"2024-10-03T12:51:27.533988Z","shell.execute_reply.started":"2024-10-03T12:48:50.351453Z","shell.execute_reply":"2024-10-03T12:51:27.532772Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2024-10-03 12:48:56,187 - INFO - Now working with All-CNN classifier\n/tmp/ipykernel_30/1378328148.py:163: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_dir / f\"{model.name}.pt\"), strict=False)\nModel Invariance Computation:   0%|          | 0/2 [00:00<?, ?batch/s]\nBatch Progress:   0%|          | 0/187 [00:00<?, ?symmetry/s]\u001b[A\nBatch Progress:  23%|██▎       | 43/187 [00:00<00:00, 420.96symmetry/s]\u001b[A\nBatch Progress:  46%|████▌     | 86/187 [00:00<00:00, 418.60symmetry/s]\u001b[A\nBatch Progress:  70%|██████▉   | 130/187 [00:00<00:00, 425.69symmetry/s]\u001b[A\nBatch Progress:  94%|█████████▎| 175/187 [00:00<00:00, 432.16symmetry/s]\u001b[A\nModel Invariance Computation:  50%|█████     | 1/2 [00:00<00:00,  2.20batch/s]\nBatch Progress:   0%|          | 0/187 [00:00<?, ?symmetry/s]\u001b[A\nBatch Progress:  25%|██▍       | 46/187 [00:00<00:00, 454.26symmetry/s]\u001b[A\nBatch Progress:  49%|████▉     | 92/187 [00:00<00:00, 449.57symmetry/s]\u001b[A\nBatch Progress:  73%|███████▎  | 137/187 [00:00<00:00, 448.60symmetry/s]\u001b[A\nBatch Progress:  97%|█████████▋| 182/187 [00:00<00:00, 448.75symmetry/s]\u001b[A\n2024-10-03 12:48:57,083 - INFO - Model invariance: 1                          \n2024-10-03 12:48:57,084 - INFO - Now working with SimplEx explainer\n/tmp/ipykernel_30/1378328148.py:171: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  torch.load(model_dir / f\"{model.name}.pt\"), strict=False\nExplanation Invariance Computation:   0%|          | 0/2 [00:00<?, ?batch/s]\nGroup Completion:   0%|          | 0/187 [00:00<?, ?symmetry/s]\u001b[A\nGroup Completion:   1%|          | 1/187 [00:00<02:39,  1.17symmetry/s]\u001b[A\nGroup Completion:   1%|          | 2/187 [00:01<02:47,  1.11symmetry/s]\u001b[A\nGroup Completion:   2%|▏         | 3/187 [00:02<02:42,  1.13symmetry/s]\u001b[A\nGroup Completion:   2%|▏         | 4/187 [00:03<02:38,  1.16symmetry/s]\u001b[A\nGroup Completion:   3%|▎         | 5/187 [00:04<02:36,  1.17symmetry/s]\u001b[A\nGroup Completion:   3%|▎         | 6/187 [00:05<02:37,  1.15symmetry/s]\u001b[A\nGroup Completion:   4%|▎         | 7/187 [00:06<02:39,  1.13symmetry/s]\u001b[A\nGroup Completion:   4%|▍         | 8/187 [00:07<02:38,  1.13symmetry/s]\u001b[A\nGroup Completion:   5%|▍         | 9/187 [00:07<02:35,  1.14symmetry/s]\u001b[A\nGroup Completion:   5%|▌         | 10/187 [00:08<02:35,  1.14symmetry/s]\u001b[A\nGroup Completion:   6%|▌         | 11/187 [00:09<02:35,  1.13symmetry/s]\u001b[A\nGroup Completion:   6%|▋         | 12/187 [00:10<02:35,  1.12symmetry/s]\u001b[A\nGroup Completion:   7%|▋         | 13/187 [00:11<02:40,  1.08symmetry/s]\u001b[A\nGroup Completion:   7%|▋         | 14/187 [00:12<02:40,  1.08symmetry/s]\u001b[A\nGroup Completion:   8%|▊         | 15/187 [00:13<02:35,  1.11symmetry/s]\u001b[A\nGroup Completion:   9%|▊         | 16/187 [00:14<02:34,  1.10symmetry/s]\u001b[A\nGroup Completion:   9%|▉         | 17/187 [00:15<02:32,  1.11symmetry/s]\u001b[A\nGroup Completion:  10%|▉         | 18/187 [00:16<02:31,  1.11symmetry/s]\u001b[A\nGroup Completion:  10%|█         | 19/187 [00:16<02:32,  1.10symmetry/s]\u001b[A\nGroup Completion:  11%|█         | 20/187 [00:17<02:28,  1.13symmetry/s]\u001b[A\nGroup Completion:  11%|█         | 21/187 [00:18<02:27,  1.13symmetry/s]\u001b[A\nGroup Completion:  12%|█▏        | 22/187 [00:19<02:26,  1.13symmetry/s]\u001b[A\nGroup Completion:  12%|█▏        | 23/187 [00:20<02:24,  1.14symmetry/s]\u001b[A\nGroup Completion:  13%|█▎        | 24/187 [00:21<02:23,  1.13symmetry/s]\u001b[A\nGroup Completion:  13%|█▎        | 25/187 [00:22<02:24,  1.12symmetry/s]\u001b[A\nGroup Completion:  14%|█▍        | 26/187 [00:23<02:22,  1.13symmetry/s]\u001b[A\nGroup Completion:  14%|█▍        | 27/187 [00:23<02:19,  1.15symmetry/s]\u001b[A\nGroup Completion:  15%|█▍        | 28/187 [00:24<02:18,  1.15symmetry/s]\u001b[A\nGroup Completion:  16%|█▌        | 29/187 [00:25<02:16,  1.16symmetry/s]\u001b[A\nGroup Completion:  16%|█▌        | 30/187 [00:26<02:16,  1.15symmetry/s]\u001b[A\nGroup Completion:  17%|█▋        | 31/187 [00:27<02:16,  1.14symmetry/s]\u001b[A\nGroup Completion:  17%|█▋        | 32/187 [00:28<02:15,  1.14symmetry/s]\u001b[A\nGroup Completion:  18%|█▊        | 33/187 [00:29<02:15,  1.14symmetry/s]\u001b[A\nGroup Completion:  18%|█▊        | 34/187 [00:30<02:14,  1.14symmetry/s]\u001b[A\nGroup Completion:  19%|█▊        | 35/187 [00:30<02:14,  1.13symmetry/s]\u001b[A\nGroup Completion:  19%|█▉        | 36/187 [00:31<02:12,  1.14symmetry/s]\u001b[A\nGroup Completion:  20%|█▉        | 37/187 [00:32<02:11,  1.14symmetry/s]\u001b[A\nGroup Completion:  20%|██        | 38/187 [00:33<02:09,  1.15symmetry/s]\u001b[A\nGroup Completion:  21%|██        | 39/187 [00:34<02:08,  1.15symmetry/s]\u001b[A\nGroup Completion:  21%|██▏       | 40/187 [00:35<02:07,  1.15symmetry/s]\u001b[A\nGroup Completion:  22%|██▏       | 41/187 [00:36<02:08,  1.13symmetry/s]\u001b[A\nGroup Completion:  22%|██▏       | 42/187 [00:37<02:07,  1.14symmetry/s]\u001b[A\nGroup Completion:  23%|██▎       | 43/187 [00:37<02:05,  1.15symmetry/s]\u001b[A\nGroup Completion:  24%|██▎       | 44/187 [00:38<02:05,  1.14symmetry/s]\u001b[A\nGroup Completion:  24%|██▍       | 45/187 [00:39<02:03,  1.15symmetry/s]\u001b[A\nGroup Completion:  25%|██▍       | 46/187 [00:40<02:02,  1.15symmetry/s]\u001b[A\nGroup Completion:  25%|██▌       | 47/187 [00:41<02:04,  1.13symmetry/s]\u001b[A\nGroup Completion:  26%|██▌       | 48/187 [00:42<02:01,  1.15symmetry/s]\u001b[A\nGroup Completion:  26%|██▌       | 49/187 [00:43<02:04,  1.11symmetry/s]\u001b[A\nGroup Completion:  27%|██▋       | 50/187 [00:44<02:03,  1.11symmetry/s]\u001b[A\nGroup Completion:  27%|██▋       | 51/187 [00:45<02:00,  1.13symmetry/s]\u001b[A\nGroup Completion:  28%|██▊       | 52/187 [00:45<01:59,  1.13symmetry/s]\u001b[A\nGroup Completion:  28%|██▊       | 53/187 [00:46<01:58,  1.14symmetry/s]\u001b[A\nGroup Completion:  29%|██▉       | 54/187 [00:47<01:56,  1.14symmetry/s]\u001b[A\nGroup Completion:  29%|██▉       | 55/187 [00:48<01:56,  1.13symmetry/s]\u001b[A\nGroup Completion:  30%|██▉       | 56/187 [00:49<01:54,  1.15symmetry/s]\u001b[A\nGroup Completion:  30%|███       | 57/187 [00:50<01:51,  1.16symmetry/s]\u001b[A\nGroup Completion:  31%|███       | 58/187 [00:51<01:52,  1.15symmetry/s]\u001b[A\nGroup Completion:  32%|███▏      | 59/187 [00:51<01:50,  1.16symmetry/s]\u001b[A\nGroup Completion:  32%|███▏      | 60/187 [00:52<01:51,  1.14symmetry/s]\u001b[A\nGroup Completion:  33%|███▎      | 61/187 [00:53<01:50,  1.14symmetry/s]\u001b[A\nGroup Completion:  33%|███▎      | 62/187 [00:54<01:49,  1.14symmetry/s]\u001b[A\nGroup Completion:  34%|███▎      | 63/187 [00:55<01:48,  1.15symmetry/s]\u001b[A\nGroup Completion:  34%|███▍      | 64/187 [00:56<01:46,  1.15symmetry/s]\u001b[A\nGroup Completion:  35%|███▍      | 65/187 [00:57<01:44,  1.16symmetry/s]\u001b[A\nGroup Completion:  35%|███▌      | 66/187 [00:58<01:43,  1.17symmetry/s]\u001b[A\nGroup Completion:  36%|███▌      | 67/187 [00:58<01:43,  1.16symmetry/s]\u001b[A\nGroup Completion:  36%|███▋      | 68/187 [00:59<01:42,  1.16symmetry/s]\u001b[A\nGroup Completion:  37%|███▋      | 69/187 [01:00<01:43,  1.14symmetry/s]\u001b[A\nGroup Completion:  37%|███▋      | 70/187 [01:01<01:44,  1.11symmetry/s]\u001b[A\nGroup Completion:  38%|███▊      | 71/187 [01:02<01:42,  1.13symmetry/s]\u001b[A\nGroup Completion:  39%|███▊      | 72/187 [01:03<01:42,  1.12symmetry/s]\u001b[A\nGroup Completion:  39%|███▉      | 73/187 [01:04<01:42,  1.12symmetry/s]\u001b[A\nGroup Completion:  40%|███▉      | 74/187 [01:05<01:39,  1.14symmetry/s]\u001b[A\nGroup Completion:  40%|████      | 75/187 [01:06<01:40,  1.12symmetry/s]\u001b[A\nGroup Completion:  41%|████      | 76/187 [01:06<01:38,  1.13symmetry/s]\u001b[A\nGroup Completion:  41%|████      | 77/187 [01:07<01:37,  1.13symmetry/s]\u001b[A\nGroup Completion:  42%|████▏     | 78/187 [01:08<01:35,  1.14symmetry/s]\u001b[A\nGroup Completion:  42%|████▏     | 79/187 [01:09<01:34,  1.15symmetry/s]\u001b[A\nGroup Completion:  43%|████▎     | 80/187 [01:10<01:32,  1.16symmetry/s]\u001b[A\nGroup Completion:  43%|████▎     | 81/187 [01:11<01:33,  1.13symmetry/s]\u001b[A\nGroup Completion:  44%|████▍     | 82/187 [01:12<01:31,  1.15symmetry/s]\u001b[A\nGroup Completion:  44%|████▍     | 83/187 [01:13<01:30,  1.15symmetry/s]\u001b[A\nGroup Completion:  45%|████▍     | 84/187 [01:13<01:28,  1.17symmetry/s]\u001b[A\nGroup Completion:  45%|████▌     | 85/187 [01:14<01:31,  1.11symmetry/s]\u001b[A\nGroup Completion:  46%|████▌     | 86/187 [01:15<01:31,  1.11symmetry/s]\u001b[A\nGroup Completion:  47%|████▋     | 87/187 [01:16<01:28,  1.13symmetry/s]\u001b[A\nGroup Completion:  47%|████▋     | 88/187 [01:17<01:26,  1.15symmetry/s]\u001b[A\nGroup Completion:  48%|████▊     | 89/187 [01:18<01:24,  1.15symmetry/s]\u001b[A\nGroup Completion:  48%|████▊     | 90/187 [01:19<01:23,  1.16symmetry/s]\u001b[A\nGroup Completion:  49%|████▊     | 91/187 [01:20<01:22,  1.17symmetry/s]\u001b[A\nGroup Completion:  49%|████▉     | 92/187 [01:20<01:21,  1.16symmetry/s]\u001b[A\nGroup Completion:  50%|████▉     | 93/187 [01:21<01:21,  1.15symmetry/s]\u001b[A\nGroup Completion:  50%|█████     | 94/187 [01:22<01:22,  1.13symmetry/s]\u001b[A\nGroup Completion:  51%|█████     | 95/187 [01:23<01:21,  1.12symmetry/s]\u001b[A\nGroup Completion:  51%|█████▏    | 96/187 [01:24<01:21,  1.12symmetry/s]\u001b[A\nGroup Completion:  52%|█████▏    | 97/187 [01:25<01:21,  1.11symmetry/s]\u001b[A\nGroup Completion:  52%|█████▏    | 98/187 [01:26<01:18,  1.13symmetry/s]\u001b[A\nGroup Completion:  53%|█████▎    | 99/187 [01:27<01:17,  1.14symmetry/s]\u001b[A\nGroup Completion:  53%|█████▎    | 100/187 [01:28<01:17,  1.12symmetry/s]\u001b[A\nGroup Completion:  54%|█████▍    | 101/187 [01:28<01:16,  1.12symmetry/s]\u001b[A\nGroup Completion:  55%|█████▍    | 102/187 [01:29<01:15,  1.13symmetry/s]\u001b[A\nGroup Completion:  55%|█████▌    | 103/187 [01:30<01:14,  1.12symmetry/s]\u001b[A\nGroup Completion:  56%|█████▌    | 104/187 [01:31<01:14,  1.12symmetry/s]\u001b[A\nGroup Completion:  56%|█████▌    | 105/187 [01:32<01:13,  1.11symmetry/s]\u001b[A\nGroup Completion:  57%|█████▋    | 106/187 [01:33<01:13,  1.11symmetry/s]\u001b[A\nGroup Completion:  57%|█████▋    | 107/187 [01:34<01:11,  1.12symmetry/s]\u001b[A\nGroup Completion:  58%|█████▊    | 108/187 [01:35<01:09,  1.14symmetry/s]\u001b[A\nGroup Completion:  58%|█████▊    | 109/187 [01:36<01:08,  1.13symmetry/s]\u001b[A\nGroup Completion:  59%|█████▉    | 110/187 [01:36<01:07,  1.15symmetry/s]\u001b[A\nGroup Completion:  59%|█████▉    | 111/187 [01:37<01:05,  1.16symmetry/s]\u001b[A\nGroup Completion:  60%|█████▉    | 112/187 [01:38<01:04,  1.17symmetry/s]\u001b[A\nGroup Completion:  60%|██████    | 113/187 [01:39<01:03,  1.16symmetry/s]\u001b[A\nGroup Completion:  61%|██████    | 114/187 [01:40<01:02,  1.16symmetry/s]\u001b[A\nGroup Completion:  61%|██████▏   | 115/187 [01:41<01:04,  1.12symmetry/s]\u001b[A\nGroup Completion:  62%|██████▏   | 116/187 [01:42<01:02,  1.14symmetry/s]\u001b[A\nGroup Completion:  63%|██████▎   | 117/187 [01:42<01:01,  1.14symmetry/s]\u001b[A\nGroup Completion:  63%|██████▎   | 118/187 [01:43<01:01,  1.12symmetry/s]\u001b[A\nGroup Completion:  64%|██████▎   | 119/187 [01:44<01:00,  1.13symmetry/s]\u001b[A\nGroup Completion:  64%|██████▍   | 120/187 [01:45<00:59,  1.12symmetry/s]\u001b[A\nGroup Completion:  65%|██████▍   | 121/187 [01:46<01:00,  1.09symmetry/s]\u001b[A\nGroup Completion:  65%|██████▌   | 122/187 [01:47<00:59,  1.10symmetry/s]\u001b[A\nGroup Completion:  66%|██████▌   | 123/187 [01:48<00:57,  1.12symmetry/s]\u001b[A\nGroup Completion:  66%|██████▋   | 124/187 [01:49<00:55,  1.14symmetry/s]\u001b[A\nGroup Completion:  67%|██████▋   | 125/187 [01:50<00:55,  1.12symmetry/s]\u001b[A\nGroup Completion:  67%|██████▋   | 126/187 [01:51<00:54,  1.11symmetry/s]\u001b[A\nGroup Completion:  68%|██████▊   | 127/187 [01:51<00:53,  1.12symmetry/s]\u001b[A\nGroup Completion:  68%|██████▊   | 128/187 [01:52<00:52,  1.13symmetry/s]\u001b[A\nGroup Completion:  69%|██████▉   | 129/187 [01:53<00:50,  1.14symmetry/s]\u001b[A\nGroup Completion:  70%|██████▉   | 130/187 [01:54<00:50,  1.14symmetry/s]\u001b[A\nGroup Completion:  70%|███████   | 131/187 [01:55<00:49,  1.14symmetry/s]\u001b[A\nGroup Completion:  71%|███████   | 132/187 [01:56<00:47,  1.15symmetry/s]\u001b[A\nGroup Completion:  71%|███████   | 133/187 [01:57<00:46,  1.15symmetry/s]\u001b[A\nGroup Completion:  72%|███████▏  | 134/187 [01:58<00:46,  1.14symmetry/s]\u001b[A\nGroup Completion:  72%|███████▏  | 135/187 [01:58<00:45,  1.13symmetry/s]\u001b[A\nGroup Completion:  73%|███████▎  | 136/187 [01:59<00:44,  1.14symmetry/s]\u001b[A\nGroup Completion:  73%|███████▎  | 137/187 [02:00<00:43,  1.14symmetry/s]\u001b[A\nGroup Completion:  74%|███████▍  | 138/187 [02:01<00:42,  1.14symmetry/s]\u001b[A\nGroup Completion:  74%|███████▍  | 139/187 [02:02<00:41,  1.15symmetry/s]\u001b[A\nGroup Completion:  75%|███████▍  | 140/187 [02:03<00:40,  1.16symmetry/s]\u001b[A\nGroup Completion:  75%|███████▌  | 141/187 [02:04<00:40,  1.15symmetry/s]\u001b[A\nGroup Completion:  76%|███████▌  | 142/187 [02:05<00:39,  1.13symmetry/s]\u001b[A\nGroup Completion:  76%|███████▋  | 143/187 [02:05<00:38,  1.15symmetry/s]\u001b[A\nGroup Completion:  77%|███████▋  | 144/187 [02:06<00:37,  1.14symmetry/s]\u001b[A\nGroup Completion:  78%|███████▊  | 145/187 [02:07<00:36,  1.15symmetry/s]\u001b[A\nGroup Completion:  78%|███████▊  | 146/187 [02:08<00:36,  1.14symmetry/s]\u001b[A\nGroup Completion:  79%|███████▊  | 147/187 [02:09<00:35,  1.13symmetry/s]\u001b[A\nGroup Completion:  79%|███████▉  | 148/187 [02:10<00:34,  1.13symmetry/s]\u001b[A\nGroup Completion:  80%|███████▉  | 149/187 [02:11<00:33,  1.13symmetry/s]\u001b[A\nGroup Completion:  80%|████████  | 150/187 [02:12<00:32,  1.13symmetry/s]\u001b[A\nGroup Completion:  81%|████████  | 151/187 [02:13<00:31,  1.13symmetry/s]\u001b[A\nGroup Completion:  81%|████████▏ | 152/187 [02:13<00:30,  1.14symmetry/s]\u001b[A\nGroup Completion:  82%|████████▏ | 153/187 [02:14<00:29,  1.15symmetry/s]\u001b[A\nGroup Completion:  82%|████████▏ | 154/187 [02:15<00:28,  1.15symmetry/s]\u001b[A\nGroup Completion:  83%|████████▎ | 155/187 [02:16<00:27,  1.16symmetry/s]\u001b[A\nGroup Completion:  83%|████████▎ | 156/187 [02:17<00:27,  1.13symmetry/s]\u001b[A\nGroup Completion:  84%|████████▍ | 157/187 [02:18<00:27,  1.09symmetry/s]\u001b[A\nGroup Completion:  84%|████████▍ | 158/187 [02:19<00:26,  1.11symmetry/s]\u001b[A\nGroup Completion:  85%|████████▌ | 159/187 [02:20<00:25,  1.10symmetry/s]\u001b[A\nGroup Completion:  86%|████████▌ | 160/187 [02:21<00:24,  1.10symmetry/s]\u001b[A\nGroup Completion:  86%|████████▌ | 161/187 [02:21<00:23,  1.10symmetry/s]\u001b[A\nGroup Completion:  87%|████████▋ | 162/187 [02:22<00:22,  1.11symmetry/s]\u001b[A\nGroup Completion:  87%|████████▋ | 163/187 [02:23<00:21,  1.11symmetry/s]\u001b[A\nGroup Completion:  88%|████████▊ | 164/187 [02:24<00:20,  1.14symmetry/s]\u001b[A\nGroup Completion:  88%|████████▊ | 165/187 [02:25<00:19,  1.13symmetry/s]\u001b[A\nGroup Completion:  89%|████████▉ | 166/187 [02:26<00:18,  1.15symmetry/s]\u001b[A\nGroup Completion:  89%|████████▉ | 167/187 [02:27<00:17,  1.16symmetry/s]\u001b[A\nGroup Completion:  90%|████████▉ | 168/187 [02:28<00:16,  1.15symmetry/s]\u001b[A\n                                                                            \r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexample_importance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[20], line 198\u001b[0m, in \u001b[0;36mexample_importance\u001b[0;34m(random_seed, latent_dim, batch_size, plot, model_name, model_dir, data_dir, n_test, n_train, recursion_depth)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_name \u001b[38;5;129;01min\u001b[39;00m model_layers:\n\u001b[1;32m    195\u001b[0m     ex_importance \u001b[38;5;241m=\u001b[39m attr_methods[attr_name](\n\u001b[1;32m    196\u001b[0m         model, X_train, Y_train\u001b[38;5;241m=\u001b[39mY_train, layer\u001b[38;5;241m=\u001b[39mmodel_layers[layer_name]\n\u001b[1;32m    197\u001b[0m     )\n\u001b[0;32m--> 198\u001b[0m     explanation_inv \u001b[38;5;241m=\u001b[39m \u001b[43mexplanation_invariance_exact\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mex_importance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     ex_importance\u001b[38;5;241m.\u001b[39mremove_hook()\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inv_model, inv_expl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(model_inv, explanation_inv):\n","File \u001b[0;32m/kaggle/working/interpretability/robustness.py:198\u001b[0m, in \u001b[0;36mexplanation_invariance_exact\u001b[0;34m(explainer, symmetry, data_loader, device, similarity)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(symmetry, Translation2D) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    195\u001b[0m     explainer, InvariantExplainer\n\u001b[1;32m    196\u001b[0m ):\n\u001b[1;32m    197\u001b[0m     explainer\u001b[38;5;241m.\u001b[39manchor \u001b[38;5;241m=\u001b[39m param\n\u001b[0;32m--> 198\u001b[0m e2 \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymmetry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m sim \u001b[38;5;241m=\u001b[39m similarity(e1, e2)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_scores \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/kaggle/working/interpretability/example.py:50\u001b[0m, in \u001b[0;36mSimplEx.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[0;32m---> 50\u001b[0m     attribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mH_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attribution\n","File \u001b[0;32m/kaggle/working/interpretability/example.py:68\u001b[0m, in \u001b[0;36mSimplEx.compute_weights\u001b[0;34m(H, H_train, n_epoch)\u001b[0m\n\u001b[1;32m     66\u001b[0m     H_approx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mij,jk->ik\u001b[39m\u001b[38;5;124m\"\u001b[39m, weights, H_train)\n\u001b[1;32m     67\u001b[0m     error \u001b[38;5;241m=\u001b[39m ((H_approx \u001b[38;5;241m-\u001b[39m H) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m---> 68\u001b[0m     \u001b[43merror\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msoftmax(preweights, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"### concept_importance","metadata":{}},{"cell_type":"code","source":"args.name == \"concept_importance\"\nconcept_importance(\n        args.seed,\n        args.latent_dim,\n        args.batch_size,\n        args.plot,\n        model_name,\n        n_test=args.n_test,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-10-03T10:23:24.312973Z","iopub.status.idle":"2024-10-03T10:23:24.313467Z","shell.execute_reply.started":"2024-10-03T10:23:24.313200Z","shell.execute_reply":"2024-10-03T10:23:24.313224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### enforce_invariance","metadata":{}},{"cell_type":"code","source":"args.name == \"enforce_invariance\"\nenforce_invariance(\n        args.seed,\n        args.latent_dim,\n        args.batch_size,\n        args.plot,\n        model_name,\n        n_test=args.n_test,\n    )\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T10:23:24.315167Z","iopub.status.idle":"2024-10-03T10:23:24.315537Z","shell.execute_reply.started":"2024-10-03T10:23:24.315360Z","shell.execute_reply":"2024-10-03T10:23:24.315379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### sensitiity_comparision","metadata":{}},{"cell_type":"code","source":"args.name == \"sensitivity_comparison\":\nsensitivity_comparison(\n        args.seed,\n        args.latent_dim,\n        args.batch_size,\n        args.plot,\n        model_name,\n        n_test=args.n_test,\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import sys\n# sys.path.append('/kaggle/working')\n# from datasets.ecg.loaders import ECGDataset\n\n# # %% [code] {\"jupyter\":{\"outputs_hidden\":false}}","metadata":{"_uuid":"44f4fa05-a881-466c-bcdd-de8dc184fe01","_cell_guid":"1c4ceb64-59fd-464c-bceb-9eef5d8f7bed","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T12:46:12.264523Z","iopub.execute_input":"2024-10-02T12:46:12.265046Z","iopub.status.idle":"2024-10-02T12:46:12.339320Z","shell.execute_reply.started":"2024-10-02T12:46:12.264968Z","shell.execute_reply":"2024-10-02T12:46:12.337083Z"},"trusted":true},"execution_count":null,"outputs":[]}]}